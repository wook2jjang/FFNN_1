{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e217c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d605263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.1+cu111\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0c264",
   "metadata": {},
   "source": [
    "## Pytorch Components\n",
    "\n",
    "### 1. torch\n",
    "\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>메인 네임스페이스입니다. Tensor 생성, tensor간의 연산 등 다양한 함수가 정의되어 있습니다. Numpy와 유사한 구조를 가집니다.</span>\n",
    "\n",
    "### 2. torch.autograd\n",
    "\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>자동 미분을 위한 함수들이 포함되어져 있습니다. 자동 미분의 on,off를 제어하는 콘텍스트 매니저(enable_grad/no_grad)나 자체 미분 가능 함수를 정의할 때 사용하는 기반 클래스인 'Function' 등이 포함되어져 있습니다.</span>\n",
    "\n",
    "### 3. torch.nn\n",
    "\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>신경망을 구축하기 위한 다양한 데이터 구조나 레이어 등이 정의되어져 있습니다. 예를 들어 RNN, LSTM과 같은 레이어, ReLU와 같은 활성화 함수, MSELoss와 같은 손실 함수들이 있습니다.</span>\n",
    "\n",
    "### 4. torch.optim\n",
    "\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>확률적 경사 하강법(Stochastic Gradient Descent, SGD)를 중심으로 한 파라미터 최적화 알고리즘이 구현되어져 있습니다.</span>\n",
    "\n",
    "\n",
    "### 5. torch.utils.data\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>SGD의 반복 연산을 실행할 때 사용하는 미니 배치용 유틸리티 함수가 포함되어져 있습니다.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94f27cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 tensor 생성\n",
    "tensor_empty = torch.empty(size=(3,2))\n",
    "tensor_zero1 = torch.zeros(size=(3,2))\n",
    "tensor_zero2 = torch.zeros_like(tensor_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e38b52a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.1275e-44, 7.1466e-44],\n",
      "        [7.1466e-44, 6.4460e-44],\n",
      "        [7.0065e-44, 6.7262e-44]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2addc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_zero1)\n",
    "print(tensor_zero2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5f644c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([1, 2, 3, 4], device='cuda:0')\n",
      "tensor([1., 2., 3., 4.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 값을 직접 전달하여 tensor 생성\n",
    "tensor_cpu = torch.tensor([1,2,3,4])\n",
    "tensor_gpu = torch.tensor([1,2,3,4], device='cuda:0') # gpu에 \n",
    "tensor_flo = torch.tensor([1,2,3,4], dtype=torch.float64)\n",
    "print(tensor_cpu)\n",
    "print(tensor_gpu)\n",
    "print(tensor_flo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b3aa91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.int64\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 데이터타입 확인\n",
    "print(tensor_cpu.dtype)\n",
    "print(tensor_gpu.dtype)\n",
    "print(tensor_flo.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7cebbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 어떤 장치에 tensor가 생성되었는지 확인\n",
    "print(tensor_cpu.device)\n",
    "print(tensor_gpu.device) # cuda:0 은 gpu사용\n",
    "print(tensor_flo.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77830abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n",
      "3\n",
      "-----------------------\n",
      "torch.Size([4])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# tensor의 크기, 차원 확인\n",
    "b = torch.randn(size=(3,3,3))\n",
    "print(b.size())\n",
    "print(b.dim())\n",
    "print('-----------------------')\n",
    "print(tensor_cpu.size())\n",
    "print(tensor_cpu.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f31d015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b04634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이로 tensor 생성\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fdc83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x = np.arange(32).reshape(4,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ef4849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]\n",
      "  [12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]\n",
      "  [20 21]\n",
      "  [22 23]]\n",
      "\n",
      " [[24 25]\n",
      "  [26 27]\n",
      "  [28 29]\n",
      "  [30 31]]]\n"
     ]
    }
   ],
   "source": [
    "print(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7d8ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_x = torch.tensor(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd4d541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5],\n",
      "         [ 6,  7]],\n",
      "\n",
      "        [[ 8,  9],\n",
      "         [10, 11],\n",
      "         [12, 13],\n",
      "         [14, 15]],\n",
      "\n",
      "        [[16, 17],\n",
      "         [18, 19],\n",
      "         [20, 21],\n",
      "         [22, 23]],\n",
      "\n",
      "        [[24, 25],\n",
      "         [26, 27],\n",
      "         [28, 29],\n",
      "         [30, 31]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(torch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3d460f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7]], dtype=torch.int32)\n",
      "tensor([[ 8,  9],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15]], dtype=torch.int32)\n",
      "tensor([8, 9], dtype=torch.int32)\n",
      "tensor(8, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 인덱싱\n",
    "print(torch_x[0])\n",
    "print(torch_x[1])\n",
    "print(torch_x[1,0])\n",
    "print(torch_x[1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4699acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadcasting\n",
    "a = torch.tensor([[1,1,1,1]])\n",
    "b = torch.tensor([[2,2,2,2],[2,2,2,2],[2,2,2,2],[2,2,2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1efd26e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 3, 3],\n",
      "        [3, 3, 3, 3],\n",
      "        [3, 3, 3, 3],\n",
      "        [3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "162b7c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 8, 8, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬곱\n",
    "# 1*2 + 1*2 + 1*2 + 1*2 = 8\n",
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f681f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 2],\n",
       "        [2, 2, 2, 2],\n",
       "        [2, 2, 2, 2],\n",
       "        [2, 2, 2, 2]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원소간의 곱\n",
    "torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a403b539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2560, -0.0742, -0.2358,  0.2535,  0.0303],\n",
       "         [-0.9521,  0.4020,  0.7963, -0.4301, -1.3356],\n",
       "         [ 1.7780,  0.5246,  0.5085, -1.4925,  0.9328],\n",
       "         [ 0.7558,  1.7817,  0.6535, -1.1937, -0.5990]],\n",
       "\n",
       "        [[-0.0928, -0.9312, -1.1898,  0.1251, -2.5063],\n",
       "         [ 0.0795, -0.2920,  0.7914,  0.6898, -0.8566],\n",
       "         [-0.4063, -0.4750, -0.1594,  1.0569,  1.1128],\n",
       "         [ 1.6156,  0.9174, -1.9552,  0.7756,  0.3969]],\n",
       "\n",
       "        [[ 0.9211,  1.5317, -1.0019,  3.3254,  0.9527],\n",
       "         [ 0.9054, -0.2068,  0.0715, -0.2406,  1.1702],\n",
       "         [ 0.3547, -1.0501,  0.1145,  0.3176,  0.4581],\n",
       "         [ 0.4895, -0.3044, -0.1503,  0.1363, -0.0607]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(size=(3,4,5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a82f73f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6948,  0.1754, -0.8092,  1.2347, -0.5077],\n",
       "        [ 0.0109, -0.0323,  0.5531,  0.0064, -0.3407],\n",
       "        [ 0.5754, -0.3335,  0.1545, -0.0393,  0.8346],\n",
       "        [ 0.9536,  0.7982, -0.4840, -0.0940, -0.0876]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1.260-0.0928+0.9211)/3\n",
    "torch.mean(a, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a07f06e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7094,  0.6585,  0.4306, -0.7157, -0.2429],\n",
       "        [ 0.2990, -0.1952, -0.6282,  0.6618, -0.4633],\n",
       "        [ 0.6677, -0.0074, -0.2415,  0.8847,  0.6301]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1.2560-0.9521+ 1.7780+ 0.7558)/4\n",
    "torch.mean(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "588d714d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2460, -0.3039,  0.4503,  0.2797],\n",
       "        [-0.9190,  0.0824,  0.2258,  0.3501],\n",
       "        [ 1.1458,  0.3399,  0.0390,  0.0221]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2560, -0.0742, -0.2358,  0.2535,  0.0303의 평균\n",
    "torch.mean(a, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fd987a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11],\n",
       "         [12, 13],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[16, 17],\n",
       "         [18, 19],\n",
       "         [20, 21],\n",
       "         [22, 23]],\n",
       "\n",
       "        [[24, 25],\n",
       "         [26, 27],\n",
       "         [28, 29],\n",
       "         [30, 31]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor(np.arange(32).reshape(4,4,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85174ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(31, dtype=torch.int32)\n",
      "torch.return_types.max(\n",
      "values=tensor([[24, 25],\n",
      "        [26, 27],\n",
      "        [28, 29],\n",
      "        [30, 31]], dtype=torch.int32),\n",
      "indices=tensor([[3, 3],\n",
      "        [3, 3],\n",
      "        [3, 3],\n",
      "        [3, 3]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(a))\n",
    "print(torch.max(a, dim=0)) #인덱스 값도 추출된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b449d194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23],\n",
       "        [24, 25, 26, 27],\n",
       "        [28, 29, 30, 31]], dtype=torch.int32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모양 변경\n",
    "torch.reshape(a, (8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "197fa56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23],\n",
       "        [24, 25, 26, 27],\n",
       "        [28, 29, 30, 31]], dtype=torch.int32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2c99e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0,  1]]],\n",
       "\n",
       "\n",
       "         [[[ 2,  3]]],\n",
       "\n",
       "\n",
       "         [[[ 4,  5]]],\n",
       "\n",
       "\n",
       "         [[[ 6,  7]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 8,  9]]],\n",
       "\n",
       "\n",
       "         [[[10, 11]]],\n",
       "\n",
       "\n",
       "         [[[12, 13]]],\n",
       "\n",
       "\n",
       "         [[[14, 15]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[16, 17]]],\n",
       "\n",
       "\n",
       "         [[[18, 19]]],\n",
       "\n",
       "\n",
       "         [[[20, 21]]],\n",
       "\n",
       "\n",
       "         [[[22, 23]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[24, 25]]],\n",
       "\n",
       "\n",
       "         [[[26, 27]]],\n",
       "\n",
       "\n",
       "         [[[28, 29]]],\n",
       "\n",
       "\n",
       "         [[[30, 31]]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(np.arange(32).reshape(4,4,1,1,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d8665fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크기가 1인 차원을 제거\n",
    "a.squeeze().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30017e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27],\n",
      "        [28, 29, 30, 31]], dtype=torch.int32)\n",
      "torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(np.arange(32).reshape(8,4))\n",
    "print(a)\n",
    "print(a.size()) # shape을 써도 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2520577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 4])\n",
      "torch.Size([8, 1, 4])\n",
      "torch.Size([8, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "b = torch.unsqueeze(a, dim=0)\n",
    "print(b.size())\n",
    "c = torch.unsqueeze(a, dim=1)\n",
    "print(c.size())\n",
    "d = torch.unsqueeze(a, dim=2)\n",
    "print(d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd22038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]], dtype=torch.int32)\n",
      "-------------------------------------------------\n",
      "tensor([[[16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]],\n",
      "\n",
      "        [[24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(np.arange(16).reshape(2,2,4))\n",
    "b = torch.tensor(np.arange(16,32).reshape(2,2,4))\n",
    "print(a)\n",
    "print('-------------------------------------------------')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2fe9a776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]],\n",
      "\n",
      "        [[24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]]], dtype=torch.int32)\n",
      "torch.Size([4, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# cat() 두 tensor를 연결해준다.\n",
    "c = torch.cat((a,b), dim=0)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "91a85eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]]], dtype=torch.int32)\n",
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "d = torch.cat((a,b), dim=1)\n",
    "print(d)\n",
    "print(d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5d812ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3, 16, 17, 18, 19],\n",
      "         [ 4,  5,  6,  7, 20, 21, 22, 23]],\n",
      "\n",
      "        [[ 8,  9, 10, 11, 24, 25, 26, 27],\n",
      "         [12, 13, 14, 15, 28, 29, 30, 31]]], dtype=torch.int32)\n",
      "torch.Size([2, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "e = torch.cat((a,b), dim=2)\n",
    "print(e)\n",
    "print(e.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68770324",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a1dfcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.3-cp38-cp38-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.43.1-cp38-cp38-win_amd64.whl.metadata (155 kB)\n",
      "     ---------------------------------------- 0.0/155.5 kB ? eta -:--:--\n",
      "     -------------------------------------  153.6/155.5 kB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 155.5/155.5 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages (from matplotlib) (6.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.7.3-cp38-cp38-win_amd64.whl (7.5 MB)\n",
      "   ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/7.5 MB 3.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.4/7.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.8/7.5 MB 6.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.7/7.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.2/7.5 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.9/7.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.6/7.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.4/7.5 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.1/7.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.9/7.5 MB 11.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.3/7.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.9/7.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.5 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.5/7.5 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.1.1-cp38-cp38-win_amd64.whl (477 kB)\n",
      "   ---------------------------------------- 0.0/477.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 477.9/477.9 kB 15.1 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.43.1-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp38-cp38-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.2/56.2 kB ? eta 0:00:00\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.1/103.1 kB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.43.1 kiwisolver-1.4.5 matplotlib-3.7.3 pyparsing-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2375f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e037f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f01586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist.py에서 우리가 실제로 사용할 load_mnist함수만 불러올게요\n",
    "from mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f2a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_trn, y_trn), (x_tst, y_tst) = load_mnist(flatten=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a801a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84e2799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fd30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_trn.shape, y_trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f84fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_tst.shape, y_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e6f3c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e8a60eadf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_trn[0].reshape(-1,28)) # mnist데이터셋은 28*28픽셀이기 때문에 28*28로 구성된다.\n",
    "## plt.imshow(x_trn[0].reshape(28,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e337b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5,   14, ..., 9978, 9984, 9994], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(y_tst==1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d14e5dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows=2 # 2x5 크기의 그리드를 생성\n",
    "n_cols=5 \n",
    "fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(10,5))\n",
    "plt.tight_layout() # 겹치지 않게함\n",
    "\n",
    "for i in range(0,10): # 0~9 반복\n",
    "    row_num = int(i/n_cols)\n",
    "    col_num = int(i%n_cols) # 현재 숫자 i에 대한 그리드 내의 행과 열의 위치를 계산\n",
    "    \n",
    "    idxs = np.argwhere(y_trn==i).reshape(-1) # 숫자 i에 해당하는 모든 이미지의 인덱스 찾기\n",
    "    \n",
    "    idx = idxs[0] # 첫 번째 이미지 인덱스 선택\n",
    "    \n",
    "    ax[row_num, col_num].imshow(x_trn[idx].reshape(-1,28)) # 선택한 이미지를 해당 위치의 서브플롯에 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c39c5ef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27656a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "# pkl확장자의 파일은 다음과 같은 방식으로 열 수 있습니다!\n",
    "\n",
    "with open(\"sample_weights/sample_weight.pkl\",\"rb\") as f: #경로의 파일을 바이너리 읽기 모드(\"rb\")로 엽니다. f에 할당\n",
    "    network = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87ca73b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b2': array([-0.01471108, -0.07215131, -0.00155692,  0.12199665,  0.11603302,\n",
       "        -0.00754946,  0.04085451, -0.08496164,  0.02898045,  0.0199724 ,\n",
       "         0.19770803,  0.04365116, -0.06518728, -0.05226324,  0.0113163 ,\n",
       "         0.03049979,  0.04060355,  0.0695399 , -0.07778469,  0.0692313 ,\n",
       "        -0.09365533,  0.0548001 , -0.03843745,  0.02123107,  0.03793406,\n",
       "        -0.02806267, -0.01818407,  0.06870425,  0.0542943 ,  0.0674368 ,\n",
       "         0.06264312, -0.0233236 , -0.01589135,  0.01860516,  0.01839287,\n",
       "        -0.01568104, -0.07422207, -0.01606729, -0.02262172, -0.01007509,\n",
       "         0.0434415 , -0.12020151,  0.02802471, -0.07591944, -0.00533499,\n",
       "        -0.08935217, -0.0181419 ,  0.0330689 , -0.01812706, -0.07689384,\n",
       "        -0.02715412, -0.03847084, -0.05315471, -0.02153288,  0.06898243,\n",
       "         0.02431128, -0.00333816,  0.00817491,  0.03911701, -0.02924617,\n",
       "         0.07184725, -0.00356748,  0.02246175,  0.03987982, -0.04921926,\n",
       "         0.02454282,  0.05875788,  0.08505439, -0.00190306, -0.03044275,\n",
       "        -0.06383366,  0.0470311 , -0.12005549,  0.03573952, -0.04293387,\n",
       "         0.03283867, -0.03347731, -0.13659105, -0.00123189,  0.00096832,\n",
       "         0.04590394, -0.02517798, -0.02073979,  0.02005584,  0.010629  ,\n",
       "         0.01902938, -0.01046924,  0.05777885,  0.04737163, -0.04362756,\n",
       "         0.07450858,  0.05077952,  0.06648835,  0.04064002, -0.00265163,\n",
       "         0.00576806, -0.09652461, -0.05131314,  0.02199687, -0.04358608],\n",
       "       dtype=float32),\n",
       " 'W1': array([[-0.00741249, -0.00790439, -0.01307499, ...,  0.01978721,\n",
       "         -0.04331266, -0.01350104],\n",
       "        [-0.01029745, -0.01616653, -0.01228376, ...,  0.01920228,\n",
       "          0.02809811,  0.01450908],\n",
       "        [-0.01309184, -0.00244747, -0.0177224 , ...,  0.00944778,\n",
       "          0.01387301,  0.03393568],\n",
       "        ...,\n",
       "        [ 0.02242565, -0.0296145 , -0.06326169, ..., -0.01012643,\n",
       "          0.01120969,  0.01027199],\n",
       "        [-0.00761533,  0.02028973, -0.01498873, ...,  0.02735376,\n",
       "         -0.01229855,  0.02407041],\n",
       "        [ 0.00027915, -0.06848375,  0.00911191, ..., -0.03183098,\n",
       "          0.00743086, -0.04021148]], dtype=float32),\n",
       " 'b1': array([-0.06750315,  0.0695926 , -0.02730473,  0.02256093, -0.22001474,\n",
       "        -0.22038847,  0.04862635,  0.13499236,  0.23342554, -0.0487357 ,\n",
       "         0.10170191, -0.03076038,  0.15482435,  0.05212503,  0.06017235,\n",
       "        -0.03364862, -0.11218343, -0.26460695, -0.03323386,  0.13610415,\n",
       "         0.06354368,  0.04679805, -0.01621654, -0.05775835, -0.03108677,\n",
       "         0.10366164, -0.0845938 ,  0.11665157,  0.21852103,  0.04437255,\n",
       "         0.03378392, -0.01720384, -0.07383765,  0.16152057, -0.10621249,\n",
       "        -0.01646949,  0.00913961,  0.10238428,  0.00916639, -0.0564299 ,\n",
       "        -0.10607515,  0.09892716, -0.07136887, -0.06349134,  0.12461706,\n",
       "         0.02242282, -0.00047972,  0.04527043, -0.15179175,  0.10716812],\n",
       "       dtype=float32),\n",
       " 'W2': array([[-0.10694039,  0.01591247, -0.44349867, ...,  0.03561032,\n",
       "          0.14045963,  0.03964241],\n",
       "        [ 0.29911557, -0.03322235, -0.08902215, ..., -0.04722451,\n",
       "         -0.0972147 ,  0.2950258 ],\n",
       "        [ 0.06576645,  0.6330455 ,  0.02325344, ...,  0.05046809,\n",
       "          0.26831996, -0.13252524],\n",
       "        ...,\n",
       "        [-0.1839421 , -0.10925075,  0.25180233, ...,  0.06017017,\n",
       "          0.11689074,  0.28868544],\n",
       "        [ 0.10001627,  0.0899286 , -0.03874066, ...,  0.15217757,\n",
       "         -0.05744234, -0.00713823],\n",
       "        [-0.02220659, -0.05105179,  0.00777963, ..., -0.531206  ,\n",
       "         -0.4042084 ,  0.0090801 ]], dtype=float32),\n",
       " 'W3': array([[-4.21735764e-01,  6.89445496e-01,  8.78510177e-02,\n",
       "         -4.83838320e-01, -1.95891604e-01, -3.11136067e-01,\n",
       "          5.49542189e-01,  5.37674278e-02, -3.05000603e-01,\n",
       "          2.75984704e-02],\n",
       "        [-5.24320543e-01, -1.43624887e-01, -4.42160573e-03,\n",
       "          4.17745829e-01,  2.15625867e-01, -2.56584466e-01,\n",
       "         -1.00939667e+00,  8.12479675e-01, -3.98552269e-02,\n",
       "          8.23425591e-01],\n",
       "        [ 6.82799876e-01, -5.12037337e-01, -4.41083580e-01,\n",
       "         -8.21710154e-02,  3.19505751e-01,  1.08093655e+00,\n",
       "          2.96021044e-01, -4.06458199e-01, -3.87590617e-01,\n",
       "         -9.11374271e-01],\n",
       "        [ 1.55144155e-01,  6.78902492e-02,  9.47823405e-01,\n",
       "         -1.68429948e-02, -5.80456555e-01,  3.27762365e-02,\n",
       "          3.62194031e-01,  7.43931830e-01, -8.67070615e-01,\n",
       "         -8.71464610e-01],\n",
       "        [ 5.05435288e-01, -2.73010045e-01, -3.86344641e-02,\n",
       "          1.62854403e-01, -6.88129485e-01,  3.32544267e-01,\n",
       "          2.02865437e-01,  9.50981900e-02,  1.51449129e-01,\n",
       "         -7.51806647e-02],\n",
       "        [-1.96135119e-01, -1.86595306e-01, -7.12956667e-01,\n",
       "          1.86611667e-01,  4.71210986e-01,  2.42333114e-01,\n",
       "         -6.10382736e-01,  7.51007020e-01, -3.54771428e-02,\n",
       "          3.63117427e-01],\n",
       "        [-3.40776503e-01,  1.12583566e+00, -7.88639635e-02,\n",
       "         -2.40077689e-01, -1.88947007e-01,  2.77629793e-01,\n",
       "          5.58597930e-02,  7.87557483e-01, -7.21895814e-01,\n",
       "         -6.01844311e-01],\n",
       "        [-5.99524677e-01,  7.77958393e-01, -6.34838939e-01,\n",
       "         -4.66428464e-03,  7.62679726e-02, -5.22314072e-01,\n",
       "         -5.41155636e-01,  1.18006003e+00, -5.90134799e-01,\n",
       "          6.01088047e-01],\n",
       "        [-3.76633376e-01,  5.10982513e-01, -2.23146994e-02,\n",
       "         -2.52363771e-01, -3.46366763e-01,  2.64313281e-01,\n",
       "          3.83371353e-01, -7.59539828e-02,  1.97959334e-01,\n",
       "         -4.29215163e-01],\n",
       "        [ 6.50213897e-01, -3.07582080e-01, -1.82832479e-01,\n",
       "          3.61862123e-01, -2.20673040e-01,  2.36749575e-01,\n",
       "          1.46889806e-01, -8.55163217e-01, -4.77893144e-01,\n",
       "          5.95522761e-01],\n",
       "        [ 9.80530322e-01, -2.83191472e-01,  4.37024772e-01,\n",
       "          3.36801678e-01, -7.04811275e-01,  5.14311731e-01,\n",
       "          3.63065779e-01,  1.93833143e-01, -9.63333666e-01,\n",
       "         -9.99653816e-01],\n",
       "        [-5.14112294e-01, -5.21245450e-02,  8.73817950e-02,\n",
       "          6.49854317e-02, -6.79773763e-02,  5.75620718e-02,\n",
       "          2.17452496e-02,  2.97408521e-01,  6.58227876e-02,\n",
       "          5.48533797e-02],\n",
       "        [-1.22029677e-01, -5.97060800e-01, -1.67890251e-01,\n",
       "         -7.57286906e-01,  3.32458198e-01,  4.26246405e-01,\n",
       "         -5.21180809e-01,  2.07759365e-01, -3.89716327e-02,\n",
       "          7.81422555e-01],\n",
       "        [ 1.54342026e-01, -3.68901044e-01,  5.82112253e-01,\n",
       "          5.15596330e-01, -5.64041555e-01, -4.99413550e-01,\n",
       "         -8.81392837e-01,  2.10159346e-01,  1.86985135e-01,\n",
       "         -4.38510999e-02],\n",
       "        [ 4.54860330e-01, -3.00265312e-01,  6.81924820e-01,\n",
       "         -2.64147162e-01, -2.18347400e-01,  1.88041180e-01,\n",
       "          3.81713420e-01, -7.35825658e-01,  2.48639315e-01,\n",
       "         -4.43372279e-01],\n",
       "        [-5.25331438e-01,  1.18984044e+00,  3.92173350e-01,\n",
       "          6.12658978e-01, -6.09629095e-01, -1.64488718e-01,\n",
       "         -4.21452105e-01, -1.57024071e-01,  4.09224838e-01,\n",
       "         -4.47212726e-01],\n",
       "        [ 6.64840162e-01, -4.77979153e-01, -2.65062183e-01,\n",
       "          6.36108816e-01, -1.42231810e+00,  3.43148038e-02,\n",
       "         -1.16741645e+00,  7.00149655e-01,  1.24187134e-01,\n",
       "          9.88344133e-01],\n",
       "        [ 9.01858881e-02,  1.87217399e-01,  2.40680173e-01,\n",
       "          2.17940882e-01, -4.56552237e-01,  1.17312826e-01,\n",
       "          1.69359997e-01, -4.43112820e-01,  3.64482552e-01,\n",
       "         -1.11816239e+00],\n",
       "        [ 4.91134822e-01, -9.00796771e-01, -5.36716223e-01,\n",
       "         -7.89842069e-01,  3.83926064e-01,  2.72480428e-01,\n",
       "         -2.04326913e-01,  1.29462862e-02,  8.45103979e-01,\n",
       "          4.70017105e-01],\n",
       "        [ 5.84113061e-01, -5.51996469e-01,  6.50859475e-01,\n",
       "          8.69455695e-01, -1.85319453e-01, -6.97416365e-01,\n",
       "         -1.75041392e-01,  9.19872299e-02, -2.56296039e-01,\n",
       "         -7.93265477e-02],\n",
       "        [-6.92425907e-01, -1.96424216e-01, -2.89716989e-01,\n",
       "          4.59242135e-01,  3.48947614e-01, -1.67159468e-01,\n",
       "          1.60998300e-01, -8.09544206e-01,  6.75078809e-01,\n",
       "          1.56182379e-01],\n",
       "        [-1.29524320e-02,  3.38228792e-01,  5.93463369e-02,\n",
       "         -6.87147900e-02, -5.87453544e-01,  7.74757266e-02,\n",
       "         -2.76282996e-01,  2.38401830e-01,  6.18681967e-01,\n",
       "         -5.51157482e-02],\n",
       "        [-1.18962085e+00,  2.37674057e-01,  7.05483854e-02,\n",
       "          2.19739154e-01,  8.16889703e-01, -3.32062960e-01,\n",
       "         -5.38534045e-01,  1.60113409e-01, -8.55953246e-02,\n",
       "          5.15658796e-01],\n",
       "        [ 4.10203546e-01,  6.13717549e-03,  5.66948950e-01,\n",
       "         -2.59074479e-01, -1.50069296e-01,  2.25018293e-01,\n",
       "          4.06786650e-01, -7.35297143e-01, -3.46720248e-01,\n",
       "         -2.61616319e-01],\n",
       "        [ 4.59970772e-01, -4.31826115e-01, -8.56852472e-01,\n",
       "          7.73031771e-01,  1.38916939e-01,  5.60679853e-01,\n",
       "          2.40944013e-01, -8.48280013e-01, -3.33365619e-01,\n",
       "          4.76054907e-01],\n",
       "        [-9.88283753e-02, -1.76046476e-01,  5.23827970e-01,\n",
       "          4.93311286e-01, -3.64566833e-01, -6.25113010e-01,\n",
       "         -1.03237808e-01,  1.33148193e-01, -2.17261493e-01,\n",
       "          4.12722528e-01],\n",
       "        [ 1.01385760e+00, -8.49169970e-01, -5.17473184e-02,\n",
       "          1.36904821e-01, -2.97809035e-01, -2.57933736e-01,\n",
       "          9.45847854e-02,  1.84433058e-01, -9.48848128e-02,\n",
       "         -1.27696171e-01],\n",
       "        [ 1.10258982e-01, -1.13074876e-01,  3.61660570e-01,\n",
       "          6.37016416e-01, -9.38879609e-01,  4.03465390e-01,\n",
       "         -8.38840306e-01,  8.87874886e-02,  6.13263905e-01,\n",
       "         -2.62609452e-01],\n",
       "        [ 3.35207991e-02, -3.10817391e-01,  6.60446942e-01,\n",
       "         -8.03743303e-02, -3.53499681e-01,  1.35674715e-01,\n",
       "          7.04031825e-01, -5.38375497e-01,  2.68499017e-01,\n",
       "         -3.45674306e-01],\n",
       "        [ 5.69811165e-01, -5.41205049e-01,  2.31889188e-02,\n",
       "          4.89905447e-01, -2.72151738e-01,  5.81560850e-01,\n",
       "         -1.45812467e-01, -6.32519484e-01,  1.47586465e-01,\n",
       "         -4.30490822e-01],\n",
       "        [-1.78033903e-01,  4.55413640e-01,  2.76871175e-01,\n",
       "          7.92362913e-02, -1.37377933e-01, -5.41430473e-01,\n",
       "          1.04435158e+00, -2.25798294e-01, -5.47417521e-01,\n",
       "         -6.21576250e-01],\n",
       "        [-3.71773511e-01,  1.31890997e-01,  9.79362205e-02,\n",
       "          6.88198984e-01, -1.36723658e-02, -4.33259517e-01,\n",
       "          2.70418584e-01,  6.90640584e-02, -7.96580434e-01,\n",
       "         -5.26694544e-02],\n",
       "        [-7.46119380e-01,  9.01669323e-01, -2.98285723e-01,\n",
       "         -6.93346620e-01,  2.22594962e-01,  3.04485057e-02,\n",
       "          6.12528384e-01,  2.91027486e-01, -6.12122193e-02,\n",
       "          2.26576433e-01],\n",
       "        [ 3.48814666e-01, -4.58619356e-01, -6.81712866e-01,\n",
       "         -8.45831633e-01,  3.85846436e-01,  3.74807537e-01,\n",
       "          6.80784345e-01,  4.05046254e-01, -3.60009670e-01,\n",
       "          4.06914890e-01],\n",
       "        [-2.68160850e-01,  1.07725048e+00, -2.42447808e-01,\n",
       "         -2.51773655e-01, -4.94481117e-01,  7.93285251e-01,\n",
       "         -1.86872244e-01,  2.33764172e-01,  7.65040368e-02,\n",
       "         -5.82407176e-01],\n",
       "        [-2.11705387e-01, -1.51310667e-01,  4.11912441e-01,\n",
       "         -3.43303621e-01,  8.63409936e-01, -1.09486476e-01,\n",
       "          3.09372574e-01,  9.14473683e-02, -8.08858573e-01,\n",
       "         -4.53698725e-01],\n",
       "        [-8.46252620e-01,  2.60528892e-01, -2.08791450e-01,\n",
       "          3.45685095e-01,  3.24550092e-01,  1.55364513e-01,\n",
       "         -7.04575300e-01, -3.74434799e-01,  6.25603318e-01,\n",
       "          2.56761312e-01],\n",
       "        [ 1.74457684e-01,  1.81623884e-02,  5.10722816e-01,\n",
       "          1.43729225e-01, -5.16600788e-01, -1.29177034e-01,\n",
       "         -2.84929127e-01,  7.80223534e-02, -1.95045814e-01,\n",
       "         -3.94748539e-01],\n",
       "        [-9.24672037e-02, -2.23728850e-01, -9.66394618e-02,\n",
       "         -4.45146620e-01,  6.13103390e-01, -3.68567199e-01,\n",
       "          3.70431751e-01,  2.21393555e-01, -2.72072498e-02,\n",
       "          5.77588558e-01],\n",
       "        [ 4.03020531e-01, -2.55338818e-01, -8.18292499e-01,\n",
       "         -7.23324642e-02, -1.96062587e-02,  1.01438415e+00,\n",
       "         -1.16559081e-01,  8.81542623e-01, -4.94637221e-01,\n",
       "          1.04218423e-01],\n",
       "        [ 2.29111224e-01,  7.30729550e-02,  1.22222453e-01,\n",
       "          3.62838387e-01, -3.36847633e-01,  3.46625239e-01,\n",
       "          4.59826976e-01, -1.19660234e+00,  6.46007299e-01,\n",
       "         -3.92430216e-01],\n",
       "        [-6.43994093e-01, -2.67290205e-01,  9.30678025e-02,\n",
       "          3.94550234e-01,  1.39838919e-01, -1.74355850e-01,\n",
       "         -6.76944792e-01, -2.02130079e-01,  7.06950128e-01,\n",
       "          5.73860466e-01],\n",
       "        [ 1.07093401e-01, -2.68440068e-01, -2.92150110e-01,\n",
       "          1.73880085e-01, -3.07512134e-01, -3.96545947e-01,\n",
       "         -1.84642792e-01,  3.94368291e-01, -4.25530560e-02,\n",
       "          3.89361382e-01],\n",
       "        [-9.44061875e-01,  3.12739849e-01,  7.40508661e-02,\n",
       "          3.96307945e-01,  5.65728784e-01, -7.04721391e-01,\n",
       "         -5.46964332e-02, -2.59483963e-01,  1.21336356e-01,\n",
       "          1.15879285e+00],\n",
       "        [-3.42181930e-03, -2.76601106e-01,  1.77765489e-01,\n",
       "         -1.00918278e-01,  5.06949902e-01,  1.84735537e-01,\n",
       "          3.32832158e-01, -2.01131087e-02, -9.75943431e-02,\n",
       "         -6.96182191e-01],\n",
       "        [ 3.78743917e-01, -1.30411685e-01,  5.25011957e-01,\n",
       "         -4.92531627e-01,  8.44208971e-02, -4.36175138e-01,\n",
       "          4.46968526e-01, -6.69526532e-02, -2.38409087e-01,\n",
       "          1.86576545e-01],\n",
       "        [-1.38466686e-01,  2.03825533e-01,  7.62569189e-01,\n",
       "          5.65001488e-01, -4.62089807e-01, -9.06799734e-02,\n",
       "         -3.04654509e-01, -3.25737983e-01,  3.49818558e-01,\n",
       "         -2.02839971e-01],\n",
       "        [ 2.19535548e-02, -5.79012573e-01, -2.61314094e-01,\n",
       "         -7.66233563e-01,  6.20492339e-01,  2.91753441e-01,\n",
       "          3.10217768e-01,  1.84355244e-01, -3.97317529e-01,\n",
       "          1.77944213e-01],\n",
       "        [ 8.36480111e-02,  1.80452511e-01, -1.26577318e-01,\n",
       "          1.01459846e-01, -4.49865282e-01,  2.09935844e-01,\n",
       "         -8.78130078e-01,  3.66405249e-01, -5.88898994e-02,\n",
       "          1.14128381e-01],\n",
       "        [ 4.04730767e-01, -2.30980113e-01, -2.02063665e-01,\n",
       "         -8.40371922e-02,  3.85631770e-01, -2.53033131e-01,\n",
       "         -7.08307028e-01,  4.86081317e-02,  5.63206136e-01,\n",
       "         -2.45178029e-01],\n",
       "        [ 1.23736739e-01,  6.76029548e-03, -4.96723533e-01,\n",
       "          1.10396254e+00,  9.44059342e-02,  1.11372745e+00,\n",
       "          1.17447861e-02, -6.46701455e-01, -4.05388534e-01,\n",
       "         -6.19069815e-01],\n",
       "        [-4.22820002e-01,  1.78682953e-01, -3.56148094e-01,\n",
       "          2.37796769e-01, -3.54685962e-01,  3.11215729e-01,\n",
       "          4.49742610e-03, -4.62334067e-01,  1.25280845e+00,\n",
       "          2.57526368e-01],\n",
       "        [ 5.01734205e-03, -2.78115179e-02,  8.33090007e-01,\n",
       "         -9.38227713e-01,  4.41729516e-01, -2.41064683e-01,\n",
       "          2.70801604e-01, -2.75141865e-01,  2.39632681e-01,\n",
       "         -2.43629783e-01],\n",
       "        [ 1.65217429e-01,  1.71752870e-01, -3.43052834e-01,\n",
       "         -6.45057321e-01,  4.53449517e-01,  1.79140553e-01,\n",
       "          4.08720821e-01, -8.79922092e-01,  4.29752409e-01,\n",
       "          3.10203969e-01],\n",
       "        [ 4.18428481e-01,  6.94155693e-01,  3.97938192e-01,\n",
       "          4.51456159e-01, -7.18708575e-01,  9.63209383e-03,\n",
       "         -4.92072105e-01,  5.09976700e-04, -2.95970529e-01,\n",
       "         -4.95860398e-01],\n",
       "        [-1.76199555e-01,  7.09368765e-01, -2.31948897e-01,\n",
       "          3.25359583e-01, -4.63672340e-01,  7.24577367e-01,\n",
       "         -4.43653435e-01, -1.68254837e-01,  2.95370251e-01,\n",
       "         -4.97434855e-01],\n",
       "        [-1.87396109e-01, -2.23947570e-01,  2.42886275e-01,\n",
       "         -2.86557496e-01,  2.73342788e-01, -1.13700256e-02,\n",
       "         -3.06602985e-01,  5.72437823e-01, -2.42054805e-01,\n",
       "          3.46188515e-01],\n",
       "        [-1.17365503e+00,  5.90703338e-02, -1.56762972e-01,\n",
       "          1.38338506e-01,  6.11611664e-01, -1.62515834e-01,\n",
       "         -2.27308512e-01,  5.09866297e-01,  7.78953657e-02,\n",
       "         -8.07275623e-03],\n",
       "        [-1.22156359e-01, -2.62149960e-01, -2.96030581e-01,\n",
       "         -6.09369529e-03,  8.27431440e-01,  1.45755662e-02,\n",
       "          1.35886416e-01,  4.84385580e-01, -6.17888629e-01,\n",
       "         -2.57963389e-01],\n",
       "        [-1.18745811e-01, -3.78561169e-02,  8.41072202e-02,\n",
       "          1.59376860e-01,  2.78664678e-01, -5.57438016e-01,\n",
       "         -1.06849708e-01,  7.62400031e-02, -1.46159276e-01,\n",
       "          6.71272278e-01],\n",
       "        [-4.58585024e-01, -2.70307302e-01,  8.93705249e-01,\n",
       "          4.14883375e-01,  5.04897237e-01, -5.52910447e-01,\n",
       "          7.95029774e-02,  3.26490283e-01, -4.37226027e-01,\n",
       "         -1.50011420e-01],\n",
       "        [-2.27586448e-01,  2.70228744e-01, -1.38651179e-02,\n",
       "         -1.68369621e-01, -6.68714801e-03,  1.84312925e-01,\n",
       "         -2.07858533e-01, -7.48970136e-02,  2.81839728e-01,\n",
       "          1.62073016e-01],\n",
       "        [-2.93510854e-01,  5.90191126e-01, -8.06541979e-01,\n",
       "          4.55247253e-01, -6.28962517e-02,  4.05282497e-01,\n",
       "         -8.00064087e-01,  1.01426566e+00, -9.47925091e-01,\n",
       "          1.12049413e+00],\n",
       "        [ 1.03260410e+00, -3.75866979e-01, -2.32749850e-01,\n",
       "          3.54511850e-02,  1.59004685e-02,  1.35123044e-01,\n",
       "         -1.82888061e-01,  5.62692165e-01, -7.38840044e-01,\n",
       "         -1.65996298e-01],\n",
       "        [-3.03140342e-01, -3.99403989e-01, -1.24023721e-01,\n",
       "          8.09619203e-02,  6.03184886e-02, -3.47880661e-01,\n",
       "         -3.64323795e-01,  7.73909748e-01, -5.57690300e-02,\n",
       "          7.16391385e-01],\n",
       "        [-9.02440190e-01,  4.48047310e-01,  3.87582779e-01,\n",
       "         -1.07054925e+00,  6.14855111e-01, -4.32848215e-01,\n",
       "          6.89762652e-01,  1.21512324e-01,  1.68398306e-01,\n",
       "         -5.61287642e-01],\n",
       "        [-6.52550608e-02,  5.19375086e-01,  2.36409321e-01,\n",
       "          1.48231626e-01, -1.71541229e-01,  4.79659773e-02,\n",
       "          6.95545554e-01, -7.34554410e-01,  5.00819862e-01,\n",
       "         -8.43456626e-01],\n",
       "        [-5.33281922e-01,  5.26653945e-01,  1.57454126e-02,\n",
       "          1.46121949e-01,  2.76504960e-02, -8.91758129e-02,\n",
       "          4.62411702e-01,  5.36043644e-02,  2.31896397e-02,\n",
       "         -6.53083622e-01],\n",
       "        [ 3.93885463e-01,  2.22290620e-01, -8.66812587e-01,\n",
       "         -4.42612439e-01, -1.09500468e-01,  3.44947040e-01,\n",
       "          4.43797231e-01, -3.26241434e-01, -1.91667125e-01,\n",
       "          2.68693328e-01],\n",
       "        [ 5.09423316e-01, -1.10831499e+00, -6.63363814e-01,\n",
       "          6.10601194e-02,  4.62890774e-01,  2.16605678e-01,\n",
       "         -2.04363316e-01, -3.48413497e-01,  5.46411932e-01,\n",
       "          1.59806624e-01],\n",
       "        [ 5.03182411e-01, -4.58128005e-01, -1.23811312e-01,\n",
       "         -7.70608895e-03, -5.03727078e-01, -1.03737101e-01,\n",
       "         -6.97336435e-01,  8.40921402e-02,  9.15018559e-01,\n",
       "          4.06962276e-01],\n",
       "        [-3.36555511e-01,  2.32747003e-01, -6.51690245e-01,\n",
       "          1.92894682e-01,  4.90722917e-02,  4.82812226e-01,\n",
       "          5.17001033e-01, -3.74707580e-01, -7.26062572e-03,\n",
       "         -2.24724170e-02],\n",
       "        [-8.20727646e-01,  2.77037054e-01, -4.00716156e-01,\n",
       "         -6.01541400e-01,  5.41227221e-01, -1.07606472e-02,\n",
       "          1.13190107e-01, -7.11759388e-01,  7.47027993e-01,\n",
       "          3.95591497e-01],\n",
       "        [-9.64956045e-01,  6.50479198e-01,  1.57247171e-01,\n",
       "          1.21039891e+00, -6.58656538e-01, -2.88676590e-01,\n",
       "         -5.25724113e-01,  6.54611349e-01, -3.65922421e-01,\n",
       "          4.67684865e-02],\n",
       "        [-4.69699763e-02, -3.76960456e-01, -8.73867750e-01,\n",
       "         -2.19822064e-01,  6.68559313e-01,  5.76594114e-01,\n",
       "         -2.38980711e-01,  1.74888268e-01, -1.48410887e-01,\n",
       "          5.87270916e-01],\n",
       "        [ 3.56634349e-01, -5.18213026e-02,  9.20258999e-01,\n",
       "         -1.40335053e-01, -4.26269978e-01, -6.22207582e-01,\n",
       "          5.75894825e-02,  5.12691498e-01, -2.06441224e-01,\n",
       "         -2.68630385e-01],\n",
       "        [-3.19506019e-01,  2.53038436e-01,  1.83337316e-01,\n",
       "         -2.11295307e-01, -5.53449214e-01, -4.45205271e-01,\n",
       "         -1.75601929e-01,  4.42056775e-01,  6.44582987e-01,\n",
       "          2.00125635e-01],\n",
       "        [-7.43463695e-01,  2.60086924e-01, -1.95406988e-01,\n",
       "         -4.23818171e-01,  8.64849150e-01, -2.67847985e-01,\n",
       "         -1.79303423e-01, -4.71354812e-01,  5.73067427e-01,\n",
       "          3.13313872e-01],\n",
       "        [-2.63424993e-01, -2.83117831e-01, -2.91389525e-01,\n",
       "          5.06457686e-01,  7.84329653e-01, -5.26254058e-01,\n",
       "          7.48095810e-01, -4.18872535e-01, -8.39335993e-02,\n",
       "          2.52932400e-01],\n",
       "        [ 4.14991900e-02, -4.03793097e-01, -1.95395365e-01,\n",
       "          2.11023405e-01,  1.32343337e-01,  2.31272504e-01,\n",
       "         -1.18078411e+00,  1.86573476e-01,  7.68505335e-02,\n",
       "          3.85415733e-01],\n",
       "        [ 1.09860265e+00, -1.09753442e+00,  3.80715638e-01,\n",
       "         -6.38348997e-01, -1.58655971e-01,  1.94847152e-01,\n",
       "         -7.95399770e-02,  9.50471818e-01, -3.16824853e-01,\n",
       "         -2.83558935e-01],\n",
       "        [-2.77928740e-01,  2.24254742e-01, -3.28038484e-01,\n",
       "          2.36775950e-01,  4.65092897e-01,  1.14463799e-01,\n",
       "         -4.18108590e-02,  1.95581898e-01, -7.47340381e-01,\n",
       "         -2.79023498e-01],\n",
       "        [ 7.56891370e-02, -1.96978986e-01,  6.49631858e-01,\n",
       "          4.44254547e-01,  4.46472913e-01, -2.43867710e-01,\n",
       "          3.44643325e-01, -6.73000336e-01,  1.98133841e-01,\n",
       "         -7.13343263e-01],\n",
       "        [ 3.50795746e-01, -2.43827224e-01,  2.70755768e-01,\n",
       "         -1.88798487e-01,  2.67679513e-01, -2.67900437e-01,\n",
       "         -2.25820035e-01,  1.41538918e-01, -6.25311971e-01,\n",
       "         -7.91989092e-04],\n",
       "        [ 6.04720116e-01, -1.23945558e+00, -9.89200622e-02,\n",
       "         -8.47476780e-01,  1.88840643e-01,  1.78689778e-01,\n",
       "          3.30614984e-01,  2.13386491e-01,  1.40828237e-01,\n",
       "          5.96347034e-01],\n",
       "        [-1.29010156e-01, -4.19559628e-01,  8.10783267e-01,\n",
       "         -7.79421180e-02, -6.39355540e-01,  1.82476446e-01,\n",
       "          4.43780273e-02,  2.43306741e-01,  3.22627991e-01,\n",
       "         -6.96950316e-01],\n",
       "        [-2.65945554e-01,  2.54204452e-01, -2.81551868e-01,\n",
       "          3.05856839e-02,  3.32366735e-01, -2.72288859e-01,\n",
       "         -1.56741664e-01,  7.37876654e-01, -3.42516750e-01,\n",
       "         -3.38515751e-02],\n",
       "        [-2.21063226e-01, -1.61017135e-01, -3.43953133e-01,\n",
       "          7.71231763e-03,  3.99634361e-01,  4.22857910e-01,\n",
       "          1.07494044e+00,  1.67980686e-01, -5.57168424e-01,\n",
       "         -9.82021630e-01],\n",
       "        [-3.34168285e-01,  4.13684517e-01,  8.20092857e-02,\n",
       "          2.00068444e-01, -6.36684000e-01,  6.32712722e-01,\n",
       "          6.26974523e-01, -7.68007815e-01,  7.41086155e-02,\n",
       "         -7.47185767e-01],\n",
       "        [-1.13031104e-01,  2.84815133e-01,  4.20125455e-01,\n",
       "         -4.12524790e-01,  2.86876053e-01, -5.96397281e-01,\n",
       "         -6.13868050e-02, -2.01329246e-01,  1.37402400e-01,\n",
       "          4.73863035e-02],\n",
       "        [-8.77382278e-01,  7.03926206e-01, -5.87477982e-01,\n",
       "          8.03793550e-01, -5.38776457e-01,  8.71291935e-01,\n",
       "         -4.21437055e-01,  1.79496706e-01, -2.01206416e-01,\n",
       "          2.20881462e-01],\n",
       "        [ 4.79993403e-01, -3.88967425e-01,  6.42738879e-01,\n",
       "         -2.66709924e-01, -2.35347107e-01, -5.27117729e-01,\n",
       "          2.24357635e-01,  4.09907281e-01, -2.55028307e-01,\n",
       "         -3.98389012e-01],\n",
       "        [-2.36967623e-01,  2.08492681e-01,  4.95875329e-02,\n",
       "         -2.54601955e-01, -1.96262509e-01,  2.20791083e-02,\n",
       "          5.87105930e-01, -1.76071987e-01, -2.93505043e-01,\n",
       "         -6.90922514e-02],\n",
       "        [ 3.72552484e-01,  1.13524333e-01,  1.47908121e-01,\n",
       "         -5.87250233e-01, -5.45590937e-01,  2.20800832e-01,\n",
       "         -1.86717466e-01, -2.76110709e-01,  1.63341820e-01,\n",
       "          9.27756205e-02],\n",
       "        [ 6.91043854e-01, -7.39305258e-01,  3.66775483e-01,\n",
       "          2.29010403e-01, -2.62648702e-01, -3.35895628e-01,\n",
       "          4.16883469e-01, -4.66414630e-01, -4.81522113e-01,\n",
       "          5.41691422e-01],\n",
       "        [-5.42117991e-02,  8.16400051e-02, -2.16311708e-01,\n",
       "         -6.47027910e-01,  4.48576599e-01, -2.78799266e-01,\n",
       "          6.27859950e-01, -3.13865662e-01,  3.10088933e-01,\n",
       "          5.49431086e-01],\n",
       "        [-4.22955692e-01,  4.71692123e-02,  5.09801149e-01,\n",
       "         -4.14053082e-01,  1.48667157e-01, -1.13204829e-01,\n",
       "          1.46537170e-01, -8.12405765e-01,  7.64870703e-01,\n",
       "         -9.93795879e-03],\n",
       "        [-4.50043291e-01,  7.81999648e-01,  2.15509236e-01,\n",
       "         -3.13456476e-01, -4.41162616e-01, -8.88375938e-02,\n",
       "          1.30276158e-01, -7.62776807e-02,  4.38656509e-01,\n",
       "         -3.53991002e-01],\n",
       "        [-5.44507623e-01,  5.37671924e-01,  2.79337078e-01,\n",
       "          6.31389797e-01, -3.13700497e-01, -9.68888775e-02,\n",
       "         -8.03692937e-01,  3.23311478e-01,  5.13087690e-01,\n",
       "         -3.67015935e-02],\n",
       "        [ 1.07227898e+00, -3.73002291e-01, -3.47672790e-01,\n",
       "         -6.34944439e-01, -2.26390660e-01,  8.66467118e-01,\n",
       "         -1.20632663e-01,  1.60931930e-01, -2.61490524e-01,\n",
       "          3.17717306e-02]], dtype=float32),\n",
       " 'b3': array([-0.06023985,  0.00932628, -0.01359946,  0.02167128,  0.0107372 ,\n",
       "         0.06619699, -0.08397342, -0.00912251,  0.00576962,  0.0532335 ],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adef5c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e214203",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2's shape: (100,), type: <class 'numpy.ndarray'>\n",
      "W1's shape: (784, 50), type: <class 'numpy.ndarray'>\n",
      "b1's shape: (50,), type: <class 'numpy.ndarray'>\n",
      "W2's shape: (50, 100), type: <class 'numpy.ndarray'>\n",
      "W3's shape: (100, 10), type: <class 'numpy.ndarray'>\n",
      "b3's shape: (10,), type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 뭐가 들어있는지 볼까요?\n",
    "for key, value in network.items():\n",
    "    print(f\"{key}'s shape: {value.shape}, type: {type(value)}\")\n",
    "    #f-string을 사용하면 문자열 내부에 중괄호 {}를 사용하여 변수나 표현식을 직접 삽입할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f01ba",
   "metadata": {},
   "source": [
    "w1: 784, 50\n",
    "w2: 50, 100\n",
    "w3: 100, 10\n",
    "\n",
    "b1: 50\n",
    "b2: 100\n",
    "b3: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa17dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist.py에서 우리가 실제로 사용할 load_mnist함수만 불러올게요\n",
    "from mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9546313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_trn, y_trn), (x_tst, y_tst) = load_mnist(flatten=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "031ba6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc9abcf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs=np.arange(0,batch_size).tolist()\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cfbaf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = x_trn[idxs]\n",
    "y_sample = y_trn[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c01b6eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "---------------------------------------------------\n",
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n",
      " 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "---------------------------------------------------\n",
      "(100, 784)\n",
      "---------------------------------------------------\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(x_sample)\n",
    "print('---------------------------------------------------')\n",
    "print(y_sample)\n",
    "print('---------------------------------------------------')\n",
    "print(x_sample.shape)\n",
    "print('---------------------------------------------------')\n",
    "print(y_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5570da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from act_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51973593",
   "metadata": {},
   "outputs": [],
   "source": [
    "## act_func.py\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def step_function(x):\n",
    "    \"\"\"\n",
    "    Return step function output\n",
    "    return=1 if >0\n",
    "    return=0 if x<=0\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    x : numpy array\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    result: numpy array\n",
    "      - consists of 0 or 1\n",
    "    \n",
    "    \"\"\"\n",
    "    y = x>0\n",
    "    return y.astype(np.int64)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    return sigmoid output\n",
    "    \"\"\"\n",
    "    result = 1/(1+np.exp(-x))\n",
    "    return result    \n",
    "    \n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    return ReLU output\n",
    "    \"\"\"\n",
    "    result = np.maximum(0,x)\n",
    "    return result\n",
    "\n",
    "def softmax(x):\n",
    "    c=np.max(x)\n",
    "    exp_x = np.exp(x-c) # overflow 대책\n",
    "    exp_sum = np.sum(exp_x)\n",
    "    result = exp_x/exp_sum\n",
    "    return result\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f20b0",
   "metadata": {},
   "source": [
    "step_function(x):\n",
    "\n",
    "**스텝 함수(Step Function)**라고 불립니다.\n",
    "입력값 x가 0보다 크면 1을 반환하고, 그렇지 않으면 0을 반환합니다.\n",
    "주로 이진 분류 문제에서 사용되며, 신경망의 초기 모델에서 사용되었습니다.\n",
    "y = x > 0은 x의 각 원소에 대해 0보다 큰지를 검사하고, 그 결과를 불리언 배열로 반환합니다.\n",
    "y.astype(np.int64)는 불리언 배열을 정수 배열(0 또는 1)로 변환합니다.\n",
    "sigmoid(x):\n",
    "\n",
    "**시그모이드 함수(Sigmoid Function)**라고 불립니다.\n",
    "출력값은 0과 1 사이입니다.\n",
    "로지스틱 회귀와 초기 신경망에서 널리 사용되었습니다.\n",
    "1 / (1 + np.exp(-x))는 시그모이드 함수의 수식입니다.\n",
    "relu(x):\n",
    "\n",
    "ReLU (Rectified Linear Unit) 함수라고 불립니다.\n",
    "입력값 x가 0보다 크면 x를 그대로 반환하고, 그렇지 않으면 0을 반환합니다.\n",
    "현대 딥 러닝 모델, 특히 컨볼루션 신경망(CNN)과 깊은 신경망에서 널리 사용됩니다.\n",
    "np.maximum(0, x)는 0과 x 중에서 큰 값을 반환합니다.\n",
    "softmax(x):\n",
    "\n",
    "**소프트맥스 함수(Softmax Function)**라고 불립니다.\n",
    "여러 클래스 중 하나로 분류하는 문제에서 출력층의 활성화 함수로 사용됩니다.\n",
    "출력값은 0과 1 사이이며, 모든 출력값의 합은 1입니다.\n",
    "c = np.max(x)와 exp_x = np.exp(x - c)는 오버플로우를 방지하기 위한 안전 조치입니다.\n",
    "exp_x / np.sum(exp_x)는 각 원소의 지수 값을 지수 값의 합으로 나누어 소프트맥스 함수의 결과를 계산합니다.\n",
    "이 함수들은 신경망에서 뉴런의 출력값을 결정하는 데 사용되는 활성화 함수들입니다. 각 함수는 특정 문제나 신경망 구조에 따라 적합한 경우가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72f55b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\Lab1_1\\act_func.py:27: RuntimeWarning: overflow encountered in exp\n",
      "  result = 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "a1 = np.dot(x_sample, W1)+b1\n",
    "z1 = sigmoid(a1)\n",
    "a2 = np.dot(z1, W2)+b2\n",
    "z2 = sigmoid(a2)\n",
    "a3 = np.dot(z2,W3)+b3\n",
    "a3 = softmax(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5f48cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.65985318e-06, 2.98940321e-08, 1.58116560e-08, 8.26428222e-05,\n",
       "        6.45305920e-10, 1.36453228e-03, 1.15899579e-09, 3.38989850e-07,\n",
       "        9.73324632e-07, 2.72354072e-07],\n",
       "       [3.40686366e-02, 1.84032806e-11, 2.71697058e-06, 2.74623432e-07,\n",
       "        3.58174401e-09, 1.35710379e-05, 4.45646037e-07, 1.39736002e-07,\n",
       "        2.49776857e-08, 2.49724881e-08],\n",
       "       [9.72917213e-09, 7.25479188e-09, 1.11345762e-05, 3.62529192e-07,\n",
       "        1.67023492e-04, 6.68745770e-09, 1.30921205e-06, 1.36441628e-07,\n",
       "        6.24422754e-08, 3.49156693e-07],\n",
       "       [1.32899594e-12, 1.32451840e-02, 1.79460694e-05, 3.40644419e-06,\n",
       "        5.17060172e-08, 6.73737901e-08, 1.12444233e-07, 1.12232861e-07,\n",
       "        6.26141900e-06, 8.10822431e-09],\n",
       "       [2.05327796e-10, 5.56673250e-08, 5.01078325e-08, 3.03691252e-07,\n",
       "        1.82125714e-05, 2.04738662e-08, 1.64209546e-09, 1.67042288e-06,\n",
       "        8.47152296e-06, 4.42205416e-03],\n",
       "       [1.23826101e-06, 1.71496028e-09, 5.15718828e-04, 2.09475820e-06,\n",
       "        6.65173605e-09, 9.50495682e-09, 3.12872728e-09, 1.37698692e-06,\n",
       "        2.42181159e-06, 1.16727460e-06],\n",
       "       [1.94063027e-13, 1.82824172e-02, 1.46777847e-06, 1.13820431e-06,\n",
       "        1.75591268e-07, 9.52358903e-08, 2.01610533e-07, 1.66821408e-07,\n",
       "        1.94171389e-05, 9.45134957e-08],\n",
       "       [1.75129600e-08, 2.63976347e-07, 7.57381429e-07, 5.06197289e-03,\n",
       "        3.49095397e-09, 9.47695185e-07, 2.15612129e-11, 1.47764425e-07,\n",
       "        5.10581322e-06, 4.14446231e-06],\n",
       "       [3.86431718e-13, 8.25784542e-03, 1.06745937e-07, 3.16750902e-06,\n",
       "        5.79791717e-08, 1.57275366e-07, 7.86446552e-09, 8.80114214e-07,\n",
       "        3.10762334e-05, 3.85966450e-06],\n",
       "       [1.70197478e-09, 1.90586347e-09, 1.68485002e-07, 1.73320780e-09,\n",
       "        4.92261676e-03, 5.87041384e-08, 3.01159844e-07, 1.10373367e-06,\n",
       "        1.12599560e-06, 1.59333067e-05],\n",
       "       [4.77694950e-09, 2.61313176e-06, 2.56411454e-06, 5.90581680e-03,\n",
       "        6.61394384e-10, 5.27750046e-07, 2.61740102e-10, 1.55670374e-08,\n",
       "        3.30369112e-05, 5.29588817e-07],\n",
       "       [1.39665724e-06, 7.51036680e-07, 5.55561201e-06, 1.00123395e-06,\n",
       "        1.06716525e-09, 1.72065702e-04, 1.01874008e-07, 3.61912877e-09,\n",
       "        1.32251207e-05, 2.61817040e-10],\n",
       "       [5.48298784e-09, 5.82531584e-07, 6.26368035e-07, 6.90417439e-02,\n",
       "        2.27544916e-09, 1.69279906e-06, 2.58827015e-10, 3.04568630e-07,\n",
       "        6.16645877e-07, 1.80296126e-07],\n",
       "       [3.24194396e-08, 1.71720117e-07, 8.08234199e-06, 1.88470151e-09,\n",
       "        2.45544470e-06, 1.36148844e-06, 2.76136678e-03, 6.20974216e-10,\n",
       "        1.45179661e-06, 2.20633667e-09],\n",
       "       [1.82241462e-12, 1.20455455e-02, 2.26443703e-07, 6.58402939e-07,\n",
       "        4.33774545e-08, 5.08011681e-07, 1.19134924e-07, 7.50062341e-08,\n",
       "        4.59164221e-05, 2.22664440e-07],\n",
       "       [6.92724385e-08, 6.69050682e-09, 4.45765629e-08, 4.61020662e-08,\n",
       "        3.66439991e-07, 3.21634872e-07, 3.88324373e-11, 3.19656320e-02,\n",
       "        1.28980545e-07, 1.80908668e-04],\n",
       "       [1.80602694e-06, 2.02207828e-09, 2.09807628e-03, 1.67439907e-06,\n",
       "        6.59907773e-09, 4.90813612e-09, 7.90267762e-08, 1.26914608e-06,\n",
       "        2.06710510e-07, 1.44611789e-07],\n",
       "       [1.76352988e-09, 3.95388327e-07, 2.00212995e-07, 2.71997152e-07,\n",
       "        1.24885560e-07, 2.83157101e-06, 1.82795166e-08, 7.61350205e-10,\n",
       "        1.14735253e-02, 3.07092205e-06],\n",
       "       [4.32980016e-07, 1.64836429e-08, 8.32767682e-07, 1.59249751e-08,\n",
       "        2.78679704e-06, 1.89454192e-06, 3.42466403e-03, 4.14000528e-10,\n",
       "        4.15966525e-07, 8.52242277e-09],\n",
       "       [1.46288936e-11, 2.64334972e-06, 3.57133390e-09, 1.17036677e-06,\n",
       "        6.63590572e-06, 1.64152397e-07, 2.48355359e-09, 1.00348029e-06,\n",
       "        1.94319036e-05, 1.66448439e-03],\n",
       "       [1.00105426e-08, 3.91106258e-09, 3.88744922e-07, 1.35523539e-08,\n",
       "        1.44788029e-03, 5.63082097e-08, 8.37988682e-06, 5.48787078e-08,\n",
       "        1.61508993e-07, 1.30253193e-06],\n",
       "       [3.99765559e-02, 5.64983824e-11, 1.18704713e-06, 8.39632264e-07,\n",
       "        5.19455312e-10, 5.78769177e-05, 3.15492521e-08, 1.71949284e-06,\n",
       "        1.42324508e-08, 1.79390103e-08],\n",
       "       [2.87150220e-10, 1.54248454e-08, 1.79269026e-08, 1.28199503e-07,\n",
       "        9.73479328e-05, 1.92333474e-08, 3.17998050e-09, 4.33020659e-06,\n",
       "        2.65306539e-06, 8.27128533e-03],\n",
       "       [2.20109629e-12, 7.76104303e-03, 5.59878436e-06, 3.70354678e-06,\n",
       "        6.12796285e-08, 1.14386978e-07, 2.15024549e-08, 2.67666053e-07,\n",
       "        6.17557771e-06, 3.12683817e-08],\n",
       "       [5.46311441e-08, 1.16546453e-05, 4.38632514e-06, 2.22270988e-04,\n",
       "        3.17238236e-10, 1.08963395e-05, 1.22326071e-06, 6.71420741e-09,\n",
       "        1.87870626e-07, 5.16558463e-10],\n",
       "       [2.95214500e-06, 5.59703288e-08, 3.10066825e-04, 4.26008846e-05,\n",
       "        1.04360368e-10, 4.03213960e-07, 2.01053236e-08, 2.10766404e-09,\n",
       "        6.16422476e-05, 6.47809628e-09],\n",
       "       [6.07509598e-11, 3.23420259e-08, 4.86889746e-08, 5.65977487e-08,\n",
       "        2.17438838e-03, 9.28632886e-08, 1.22911274e-07, 2.78993070e-07,\n",
       "        4.80301833e-06, 1.69341674e-05],\n",
       "       [2.06219539e-08, 7.25235793e-07, 1.45947697e-05, 1.22497333e-02,\n",
       "        1.54092877e-10, 3.80620719e-07, 5.27128306e-11, 3.65769978e-07,\n",
       "        4.10144685e-06, 3.05370179e-07],\n",
       "       [1.55675068e-07, 4.48361703e-08, 6.94974966e-04, 3.65549968e-05,\n",
       "        3.01665276e-10, 3.74384115e-08, 2.27543054e-10, 3.65236374e-05,\n",
       "        8.86168948e-07, 8.25189659e-08],\n",
       "       [1.61395577e-10, 4.72710468e-07, 6.20405160e-07, 8.90205865e-09,\n",
       "        7.40138466e-06, 1.66022041e-08, 2.03600692e-09, 4.18222335e-04,\n",
       "        1.21820699e-06, 5.47139498e-05],\n",
       "       [1.55978577e-10, 9.54825373e-06, 7.82775987e-06, 5.08827344e-03,\n",
       "        3.05120040e-09, 1.43552512e-07, 5.17131449e-09, 2.56332356e-07,\n",
       "        3.43233614e-06, 3.77773439e-08],\n",
       "       [8.69716210e-09, 6.65676282e-07, 4.32956722e-06, 6.28491325e-05,\n",
       "        3.30716099e-09, 1.95894998e-07, 6.51249721e-10, 8.17537948e-09,\n",
       "        8.07953707e-04, 1.19838296e-06],\n",
       "       [1.43300656e-06, 8.97853880e-09, 1.02991244e-05, 4.39406422e-09,\n",
       "        8.23098253e-06, 1.33103958e-06, 3.54326665e-02, 9.56192459e-09,\n",
       "        1.36988298e-09, 3.98940853e-10],\n",
       "       [1.10131730e-10, 5.74829755e-07, 4.71764183e-09, 2.37708235e-07,\n",
       "        1.08527811e-05, 7.02347975e-08, 4.66861327e-10, 4.54225024e-04,\n",
       "        3.15743421e-07, 1.70068198e-03],\n",
       "       [8.04797237e-05, 2.15027426e-10, 7.02394254e-06, 5.66340077e-07,\n",
       "        1.37398413e-08, 4.32164001e-07, 1.68703835e-07, 6.46702292e-09,\n",
       "        1.20595141e-05, 3.58629677e-07],\n",
       "       [1.26002206e-07, 7.86206499e-07, 1.70781291e-08, 1.12355265e-05,\n",
       "        6.35428954e-09, 3.40150855e-03, 1.16228263e-08, 6.94014135e-09,\n",
       "        1.09694165e-05, 6.33024078e-09],\n",
       "       [1.10915943e-08, 2.84431303e-06, 7.38156905e-06, 5.22862855e-08,\n",
       "        3.67063251e-07, 1.78031928e-06, 2.64733983e-03, 5.91536958e-11,\n",
       "        2.66473194e-06, 5.56947766e-10],\n",
       "       [1.04884664e-03, 9.71251135e-11, 2.02802948e-06, 1.13038375e-07,\n",
       "        2.98299234e-08, 1.02188744e-06, 6.98819974e-07, 5.88956404e-08,\n",
       "        3.04915915e-07, 1.48108242e-07],\n",
       "       [5.06959696e-10, 1.06322062e-07, 2.21693772e-05, 3.45378771e-06,\n",
       "        3.01545498e-07, 9.63112701e-10, 2.35057723e-10, 1.33930787e-03,\n",
       "        1.76449078e-07, 4.80490089e-05],\n",
       "       [1.01346711e-06, 1.25413446e-09, 1.74563013e-06, 5.71124348e-09,\n",
       "        5.77985384e-06, 1.23538712e-07, 3.34017706e-04, 2.16728608e-08,\n",
       "        1.45085608e-07, 2.88323719e-07],\n",
       "       [4.50467110e-13, 2.28506215e-02, 4.57432719e-07, 2.87474677e-06,\n",
       "        2.98157019e-08, 1.38166783e-07, 2.86176700e-08, 4.85447174e-07,\n",
       "        1.31585548e-05, 6.27374163e-07],\n",
       "       [2.48377141e-09, 4.02741648e-07, 5.83655186e-08, 4.51734991e-07,\n",
       "        1.05946953e-07, 6.04324850e-06, 1.69550365e-08, 6.13589790e-10,\n",
       "        9.68858227e-03, 4.85074861e-06],\n",
       "       [2.91389246e-09, 1.96111841e-07, 9.60161174e-07, 1.03512002e-06,\n",
       "        1.13877849e-08, 8.49201882e-08, 2.27006695e-11, 1.30979037e-02,\n",
       "        3.23520368e-07, 8.88891882e-05],\n",
       "       [1.25799995e-11, 1.84802354e-06, 5.19112586e-10, 2.51972938e-06,\n",
       "        7.80235223e-06, 3.62082062e-07, 1.16083802e-10, 1.04984720e-05,\n",
       "        7.73014017e-06, 1.73444096e-02],\n",
       "       [1.89652205e-09, 1.13995225e-06, 9.09700645e-07, 1.13270795e-02,\n",
       "        1.06888032e-09, 7.52942242e-07, 1.56164560e-11, 1.31403658e-06,\n",
       "        7.58901660e-06, 1.71921749e-06],\n",
       "       [1.84850441e-10, 1.93303435e-08, 7.42905915e-09, 5.58503302e-07,\n",
       "        2.98404702e-05, 5.53265380e-08, 2.53928822e-10, 1.01659925e-05,\n",
       "        4.28867406e-06, 2.32299995e-02],\n",
       "       [1.38670799e-07, 5.26250119e-08, 1.03954553e-05, 3.28570877e-07,\n",
       "        4.53416105e-09, 8.20985861e-07, 8.63405702e-09, 3.85641030e-09,\n",
       "        1.98976882e-03, 4.42341644e-07],\n",
       "       [4.71885505e-06, 3.46651134e-08, 2.04377582e-08, 1.12641146e-06,\n",
       "        5.99593530e-09, 4.81463736e-03, 3.27812941e-08, 1.65903580e-09,\n",
       "        2.89054460e-05, 1.16110277e-08],\n",
       "       [8.51383131e-10, 1.92117136e-06, 6.16811047e-09, 2.79278349e-04,\n",
       "        5.44617418e-09, 3.17893173e-05, 1.29424055e-10, 1.18685352e-06,\n",
       "        1.97576846e-05, 7.43393230e-06],\n",
       "       [6.44760023e-09, 1.37242716e-06, 3.62638474e-07, 1.59645863e-02,\n",
       "        8.58438820e-10, 3.41311716e-06, 2.26269680e-11, 1.65499827e-07,\n",
       "        5.39262828e-06, 1.92801554e-06],\n",
       "       [4.34568719e-08, 4.24581089e-07, 3.86564096e-07, 1.07823173e-02,\n",
       "        1.35716038e-09, 1.01838750e-05, 8.36674729e-09, 3.81175758e-09,\n",
       "        3.63169556e-06, 2.96787643e-08],\n",
       "       [1.98964272e-02, 2.15395098e-11, 4.44011903e-07, 2.87410074e-07,\n",
       "        2.34883069e-09, 6.32033334e-05, 1.08982654e-08, 5.24455686e-07,\n",
       "        9.70128866e-08, 2.92966689e-07],\n",
       "       [8.93763081e-06, 5.13019982e-09, 1.68035712e-07, 3.66977679e-06,\n",
       "        5.16700349e-10, 3.07006098e-06, 2.17132926e-11, 1.05601419e-02,\n",
       "        4.88043597e-08, 6.42888290e-06],\n",
       "       [4.57295053e-12, 2.66043571e-06, 7.06011249e-10, 2.41332117e-07,\n",
       "        1.02757569e-03, 2.31934519e-06, 3.32208486e-07, 1.66127529e-06,\n",
       "        2.22453465e-07, 9.42361203e-06],\n",
       "       [1.24468802e-09, 6.21397556e-09, 1.08110775e-07, 4.61938015e-07,\n",
       "        7.71872146e-06, 1.15620828e-07, 1.07214937e-09, 4.15456299e-07,\n",
       "        7.02913239e-05, 5.94247482e-04],\n",
       "       [3.26189159e-10, 1.01910985e-06, 7.15875501e-08, 8.42867485e-06,\n",
       "        1.12891541e-07, 2.08236725e-06, 3.08249398e-10, 3.34308474e-08,\n",
       "        9.82683850e-04, 1.30819790e-05],\n",
       "       [4.00121771e-02, 3.92314722e-11, 2.52242194e-06, 8.85787514e-08,\n",
       "        1.01678810e-09, 5.23009548e-05, 1.74234444e-07, 6.92034305e-08,\n",
       "        2.65322086e-07, 1.67920771e-08],\n",
       "       [1.02708897e-10, 1.86180742e-08, 4.21755697e-09, 1.21727965e-07,\n",
       "        3.83399572e-04, 3.62684638e-08, 1.92077843e-09, 1.43290063e-05,\n",
       "        9.94224138e-07, 1.47023313e-02],\n",
       "       [1.07607268e-09, 7.06074976e-09, 3.36045716e-08, 2.93603684e-08,\n",
       "        3.45515343e-03, 1.64458569e-07, 1.86409397e-06, 8.12555925e-08,\n",
       "        2.30847149e-07, 1.29618547e-05],\n",
       "       [7.16016092e-12, 1.53834950e-02, 9.03359705e-06, 6.44482782e-07,\n",
       "        3.43405837e-08, 3.33726973e-07, 1.64483424e-06, 1.11200107e-08,\n",
       "        7.71192299e-06, 2.15758811e-09],\n",
       "       [2.89056374e-07, 7.45824166e-11, 4.27928683e-07, 1.12370568e-09,\n",
       "        5.27783355e-04, 7.14694082e-08, 1.67466979e-07, 2.13965154e-06,\n",
       "        4.02707087e-07, 2.66906991e-05],\n",
       "       [7.15956322e-11, 5.92856573e-08, 1.22662387e-08, 4.00235471e-08,\n",
       "        3.47365206e-03, 3.90712216e-07, 1.23145901e-06, 6.30673185e-08,\n",
       "        1.57030524e-06, 9.03266755e-06],\n",
       "       [3.71301923e-07, 3.31818519e-08, 3.13650571e-06, 2.56532768e-08,\n",
       "        9.05630543e-07, 6.95140898e-07, 1.70131470e-03, 2.64083977e-10,\n",
       "        1.30473484e-06, 6.70174538e-09],\n",
       "       [2.66370334e-04, 4.31668035e-11, 4.01566524e-07, 3.56469883e-07,\n",
       "        6.52453878e-08, 1.38840630e-06, 1.47624339e-08, 6.32995807e-07,\n",
       "        4.27398447e-07, 3.65418032e-06],\n",
       "       [5.79880464e-07, 1.51556975e-10, 9.99228291e-08, 3.34147487e-10,\n",
       "        5.34723222e-04, 8.33594868e-07, 1.30714352e-06, 5.72003671e-07,\n",
       "        4.57674929e-07, 3.26584495e-06],\n",
       "       [1.29418503e-08, 1.05546005e-05, 2.75835408e-08, 2.60439151e-06,\n",
       "        1.04777111e-08, 8.68412550e-04, 8.50462172e-08, 1.08835208e-09,\n",
       "        1.12461719e-04, 4.22032542e-09],\n",
       "       [5.48704691e-07, 1.62592588e-08, 1.73933358e-06, 1.04961593e-07,\n",
       "        3.48196522e-06, 6.02735327e-07, 4.18507587e-03, 3.23605642e-10,\n",
       "        7.02366734e-08, 7.35352357e-09],\n",
       "       [8.47026388e-13, 3.36094536e-02, 3.23622044e-06, 1.29029945e-06,\n",
       "        2.80701489e-08, 1.87809704e-07, 1.62778051e-07, 1.15611904e-07,\n",
       "        1.18310118e-05, 2.67406968e-08],\n",
       "       [2.80665280e-03, 3.45984325e-10, 1.28620268e-05, 1.37043841e-07,\n",
       "        1.50775958e-09, 3.42670573e-05, 3.49106728e-07, 9.84520820e-09,\n",
       "        1.32400567e-06, 2.55543009e-09],\n",
       "       [1.27352178e-02, 6.78925180e-11, 5.21546144e-06, 5.13820112e-07,\n",
       "        9.78395254e-10, 1.29380551e-05, 9.34420541e-08, 7.59008003e-08,\n",
       "        2.13354383e-07, 2.09475832e-08],\n",
       "       [5.46373657e-09, 1.74869449e-04, 2.74130056e-04, 1.84855344e-05,\n",
       "        3.29653353e-11, 6.59199657e-07, 5.26005010e-07, 3.40145760e-08,\n",
       "        3.42087583e-06, 3.42903816e-10],\n",
       "       [3.76259734e-08, 1.30062263e-08, 1.16284419e-07, 5.47720482e-08,\n",
       "        3.81960660e-07, 1.13396950e-07, 5.96149102e-11, 1.60117019e-02,\n",
       "        1.82059196e-07, 1.10226014e-04],\n",
       "       [5.95534743e-13, 3.17799412e-02, 8.73659133e-07, 1.09316068e-06,\n",
       "        6.13202005e-08, 2.05942314e-07, 1.98068847e-07, 1.25749395e-07,\n",
       "        1.06427688e-05, 8.10630993e-08],\n",
       "       [1.25230699e-07, 2.20063811e-07, 2.18243022e-05, 3.52866820e-08,\n",
       "        3.27685939e-07, 2.30175331e-07, 5.53999655e-03, 2.81391660e-10,\n",
       "        3.11137143e-07, 2.86781421e-09],\n",
       "       [3.62363273e-09, 1.26533138e-07, 1.71238419e-08, 5.88575518e-03,\n",
       "        1.30023938e-08, 7.55681276e-06, 4.54874333e-11, 6.08555126e-07,\n",
       "        4.81452389e-06, 1.45842778e-05],\n",
       "       [3.90789425e-03, 1.87769300e-10, 8.03046930e-07, 4.03748254e-06,\n",
       "        7.12151393e-10, 1.43878042e-05, 2.07755790e-09, 1.57257421e-06,\n",
       "        8.04197597e-08, 3.16718143e-07],\n",
       "       [3.01443720e-07, 1.18758271e-06, 2.60011759e-03, 1.53856708e-05,\n",
       "        9.43698730e-11, 1.65798070e-07, 9.83099042e-08, 4.72780304e-09,\n",
       "        1.62124270e-05, 6.69544309e-10],\n",
       "       [8.29810960e-12, 1.35614183e-02, 1.23912810e-06, 1.26733300e-06,\n",
       "        5.07058617e-09, 2.59836440e-07, 1.05205913e-07, 4.92091417e-08,\n",
       "        3.19454666e-05, 1.48632637e-07],\n",
       "       [1.83779446e-12, 9.59444093e-04, 1.66036079e-05, 5.87685292e-07,\n",
       "        8.44114652e-07, 6.26072927e-09, 6.16477394e-08, 1.67564201e-06,\n",
       "        1.12141970e-06, 3.50763656e-07],\n",
       "       [1.38718992e-08, 2.32887309e-08, 6.65092728e-08, 2.64425459e-08,\n",
       "        1.37941322e-06, 7.77418734e-08, 1.31177375e-10, 1.15528973e-02,\n",
       "        1.05886350e-07, 2.54047656e-04],\n",
       "       [2.67342239e-06, 5.86605120e-09, 1.22074118e-06, 5.22228731e-07,\n",
       "        9.64720037e-09, 5.36204595e-07, 4.01590796e-08, 1.59983983e-07,\n",
       "        2.69366192e-05, 3.30842937e-07],\n",
       "       [3.10425125e-02, 4.66391994e-11, 2.89441323e-06, 3.08682331e-07,\n",
       "        7.00161762e-10, 3.29490467e-05, 6.36610835e-08, 9.98115866e-08,\n",
       "        2.30718157e-07, 2.04558521e-08],\n",
       "       [1.12226280e-06, 9.17930336e-08, 8.16212874e-03, 3.79563926e-06,\n",
       "        1.43445089e-09, 1.82455480e-07, 1.10311657e-05, 1.35660139e-09,\n",
       "        1.72994567e-06, 3.81495391e-11],\n",
       "       [9.11937377e-07, 1.83310345e-08, 2.33826850e-05, 1.18261312e-08,\n",
       "        6.85400948e-07, 1.65185241e-07, 3.76786385e-03, 2.36371100e-09,\n",
       "        5.19680796e-08, 7.42322337e-09],\n",
       "       [2.23904578e-07, 2.12755893e-08, 1.21436460e-05, 2.04532902e-04,\n",
       "        7.12308990e-10, 3.58365213e-08, 8.06764724e-12, 7.25919520e-03,\n",
       "        1.23792203e-08, 1.19940669e-05],\n",
       "       [1.49320889e-10, 4.77286812e-06, 1.54549511e-07, 4.20815690e-04,\n",
       "        1.69877641e-08, 1.00308421e-06, 9.67047692e-11, 1.64650267e-08,\n",
       "        9.32890573e-04, 6.33067339e-06],\n",
       "       [5.93497163e-09, 7.14882162e-08, 8.09042362e-08, 1.40045804e-03,\n",
       "        4.73060791e-09, 6.13965631e-06, 4.49504566e-11, 2.60738875e-06,\n",
       "        6.02985710e-06, 6.35291190e-06],\n",
       "       [3.34259842e-09, 5.99681638e-09, 1.28430045e-07, 1.80209298e-07,\n",
       "        3.71674446e-06, 1.53036996e-08, 2.45928528e-10, 1.53442616e-05,\n",
       "        5.95894335e-06, 7.95335416e-03],\n",
       "       [1.64806601e-02, 2.84793196e-11, 1.01281114e-06, 3.55002584e-07,\n",
       "        2.38119147e-09, 3.08134986e-05, 3.92479933e-08, 2.07651993e-07,\n",
       "        8.60498588e-08, 1.37077706e-07],\n",
       "       [2.04265138e-08, 5.67114244e-10, 8.88099194e-08, 9.87829041e-10,\n",
       "        3.49883689e-03, 1.96142665e-07, 7.76361105e-07, 3.60141144e-07,\n",
       "        6.85865871e-07, 1.18783018e-05],\n",
       "       [4.00770716e-07, 1.78018524e-08, 5.46253659e-06, 8.14968593e-10,\n",
       "        1.15779067e-05, 1.30639580e-06, 1.19816381e-02, 9.62356195e-10,\n",
       "        7.18650028e-08, 3.30056982e-09],\n",
       "       [1.35258915e-07, 4.01300060e-09, 1.86480680e-08, 5.59687869e-08,\n",
       "        5.41391273e-07, 7.59841157e-07, 7.73575509e-11, 4.71438915e-02,\n",
       "        4.12959196e-08, 8.15879030e-05],\n",
       "       [4.96330221e-09, 1.09401732e-09, 3.44708759e-08, 6.21073992e-09,\n",
       "        7.78552890e-03, 1.08974810e-07, 3.37915026e-07, 4.65026801e-07,\n",
       "        2.37557984e-07, 4.68482176e-05],\n",
       "       [7.01426259e-08, 2.80904089e-07, 4.06104255e-06, 2.79711969e-08,\n",
       "        6.65039238e-07, 8.32450837e-07, 5.27615286e-03, 2.90461322e-10,\n",
       "        5.31566286e-07, 2.29955477e-09],\n",
       "       [9.72107950e-10, 6.36441257e-07, 2.53599836e-07, 1.31692900e-07,\n",
       "        3.79691869e-07, 4.16100829e-06, 4.67819099e-08, 4.38180103e-10,\n",
       "        1.17125465e-02, 7.48169384e-07],\n",
       "       [2.42776182e-02, 3.62224001e-11, 2.97805536e-06, 3.62106277e-07,\n",
       "        1.97034900e-09, 2.28312656e-05, 2.84804372e-07, 5.00062427e-08,\n",
       "        8.39946495e-08, 1.84001134e-08],\n",
       "       [2.32565966e-08, 4.79327085e-08, 2.19597473e-06, 2.62755566e-06,\n",
       "        6.21367846e-09, 8.00853002e-08, 1.27631248e-11, 3.18783782e-02,\n",
       "        5.99796408e-08, 3.62489118e-05],\n",
       "       [1.89848004e-09, 3.65255147e-07, 2.05687343e-07, 2.60899185e-07,\n",
       "        1.24522472e-07, 2.86630416e-06, 1.77520416e-08, 7.88610621e-10,\n",
       "        1.12619242e-02, 3.08997619e-06],\n",
       "       [6.41094400e-10, 5.40082965e-07, 4.18284323e-08, 1.19682169e-02,\n",
       "        1.50295119e-08, 1.30460057e-06, 1.69369900e-11, 1.08907557e-06,\n",
       "        6.47561092e-06, 2.35916214e-05],\n",
       "       [6.53802641e-13, 4.10405872e-03, 1.71101453e-06, 8.71364989e-07,\n",
       "        2.51944584e-06, 1.63864353e-08, 5.69345850e-08, 2.99989551e-06,\n",
       "        4.16256228e-07, 3.04119624e-07]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7106669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(a3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d399ac2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0,\n",
       "       9, 1, 3, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "       3, 9, 8, 5, 3, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5,\n",
       "       6, 1, 0, 0, 2, 7, 1, 6, 3, 0, 2, 1, 1, 7, 8, 0, 2, 6, 7, 8, 3, 9,\n",
       "       0, 4, 6, 7, 4, 6, 8, 0, 7, 8, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(a3, axis=1) # softmax값이 최대인 class로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39c2888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n",
      " 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_sample[idxs]) # 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d33af0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in range(0,x_trn.shape[0],batch_size):\n",
    "    start_idx = i\n",
    "    end_idx = i+batch_size\n",
    "    x_sample = x_trn[start_idx:end_idx]\n",
    "    \n",
    "    a1 = np.dot(x_sample, W1)+b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2)+b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2,W3)+b3\n",
    "    a3 = softmax(a3)\n",
    "    \n",
    "    result.extend(np.argmax(a3, axis=1)) # 결과를 누적해서 저장하기\n",
    "    \n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af8a6262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "600e2628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result == y_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7ebf3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55511"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result == y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd43e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미리 학습한 모델의 정확도는 92.52%입니다.\n"
     ]
    }
   ],
   "source": [
    "print(f'미리 학습한 모델의 정확도는 {100*np.sum(result==y_trn) / len(y_trn):.2f}%입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8cef494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 3.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result1 = []\n",
    "for i in range(x_trn.shape[0]):\n",
    "    x_sample = x_trn[i]\n",
    "    a1 = np.dot(x_sample, W1)+b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2)+b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2,W3)+b3\n",
    "    a3 = softmax(a3)\n",
    "    \n",
    "    result1.append(np.argmax(a3))\n",
    "result1 = np.array(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96fcf328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 161 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result2 = []\n",
    "for i in range(0,x_trn.shape[0],batch_size):\n",
    "    start_idx = i\n",
    "    end_idx = i+batch_size\n",
    "    x_sample = x_trn[start_idx:end_idx]\n",
    "    a1 = np.dot(x_sample, W1)+b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2)+b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2,W3)+b3\n",
    "    a3 = softmax(a3)\n",
    "    \n",
    "    result2.extend(np.argmax(a3, axis=1))\n",
    "result2 = np.array(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c62e6d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[5 0 4 ... 5 6 8]\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(result1)\n",
    "print(result2)\n",
    "print(np.sum(result1==result2)) #시간은 빠르지만 성ㄴ능은 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53229217",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2723657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "# 신경망을 구축하기 위한 다양한 데이터 구조나 레이어 등이 정의\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# sample data제공 \n",
    "# 데이터를 입력하기 전에 전처리하는 함수 제공\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 미니배치 데이터 자동 생성\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22d6916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data2\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42.3%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data2\\MNIST\\raw\\train-images-idx3-ubyte.gz to data2\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data2\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data2\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data2\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data2\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data2\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data2\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data2\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data2\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data2\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\wook\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# torchvision에서도 MNIST데이터를 제공합니다. \n",
    "# 이 데이터를 다운 받을 디렉토리(data_path) 존재 여부를 확인하고 존재하지 않으면 생성 \n",
    "data_path = 'data2'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    \n",
    "# data 변환 방법 선언 (data transform method)\n",
    "# 아래 예시: numpy형태의 데이터를 받으면 걔를 tensor로 변환해줘!\n",
    "\n",
    "# PyTorch의 torchvision 라이브러리에서 제공하는 이미지 전처리 기능 중 하나\n",
    "# Compose는 전처리과정을 합치는것, ToTensor는 정규화 전처리 과정\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# dataset을 생성 (torchvision에서 제공하는 데이터를 다운 받고, 위의 방법대로 변환)\n",
    "trn_dset = datasets.MNIST(root=data_path, \n",
    "                          train=True, \n",
    "                          transform=transform, \n",
    "                          download=True)\n",
    "\n",
    "tst_dset = datasets.MNIST(root=data_path, \n",
    "                          train=False, \n",
    "                          transform=transform, \n",
    "                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3a20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10000\n",
    "trn_loader = DataLoader(dataset=trn_dset, # 학습데이터로 mini-batch생성기를 만들거야\n",
    "                        batch_size=BATCH_SIZE, # mini-batch의 크기는 BATCH_SIZE이고\n",
    "                        shuffle=False, # 데이터의 순서를 섞어서 만들어줘\n",
    "                        drop_last=False) # MIni-batch를 만들고 남는 데이터는 버려줘\n",
    "\n",
    "# tst_loader = DataLoader(dataset=tst_dset, # 시험데이터로 mini-batch생성기를 만들거야\n",
    "#                         batch_size=BATCH_SIZE, # mini-batch의 크기는 BATCH_SIZE이고\n",
    "#                         shuffle=False, # 데이터의 순서를 섞지말고 만들어줘\n",
    "#                         drop_last=False) # MIni-batch를 만들고 남는 데이터도 활용해줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f51e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module): # nn.Module을 상속받아서 MyNet이라는 class를 생성한다.\n",
    "    def __init__(self, in_dim, h1_dim, h2_dim, out_dim):\n",
    "        super(MyNet, self).__init__() # 요건 습관처럼 쓰세요.\n",
    "        \n",
    "        # (1) 네트워크 구조 짜기 (with 단위 모듈)\n",
    "        self.fc1 = nn.Linear(in_dim, h1_dim) # input->1st hidden layer에 대한 FFNN\n",
    "        self.fc2 = nn.Linear(h1_dim, h2_dim) # 1st->2nd hidden layer에 대한 FFNN\n",
    "        self.fc3 = nn.Linear(h2_dim, out_dim) # 2nd->output layer에 대한 FFNN\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (2) Input Flow 짜기\n",
    "        h1 = self.fc1(x) # step2\n",
    "        h1 = F.sigmoid(h1) # step3\n",
    "        h2 = self.fc2(h1) # step4\n",
    "        h2 = F.sigmoid(h2) # step5\n",
    "        h3 = self.fc3(h2) # step6\n",
    "        out = F.softmax(h3, dim=1) # step7\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05c8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e70cbea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd0c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNet(in_dim=784, # 입력하는 데이터의 차원 (784)\n",
    "            h1_dim=50, # 1st hidden layer의 neuron 수 (50)\n",
    "            h2_dim=100, # 2nd hidden layer의 neuron 수 (100)\n",
    "            out_dim=10) # data의 class 수 = output layer의 neuron 수(10)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e7aa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNet(\n",
       "  (fc1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1fc7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'sample_weights/sample_weight.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    network = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290909e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc1.weight = nn.Parameter(torch.Tensor(network['W1'].T).to(device))\n",
    "net.fc2.weight = nn.Parameter(torch.Tensor(network['W2'].T).to(device))\n",
    "net.fc3.weight = nn.Parameter(torch.Tensor(network['W3'].T).to(device))\n",
    "\n",
    "net.fc1.bias = nn.Parameter(torch.Tensor(network['b1']).to(device))\n",
    "net.fc2.bias = nn.Parameter(torch.Tensor(network['b2']).to(device))\n",
    "net.fc3.bias = nn.Parameter(torch.Tensor(network['b3']).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d672792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784]) torch.Size([10000])\n",
      "[5 0 4 ... 6 9 7]\n"
     ]
    }
   ],
   "source": [
    "for i, (x_trn, y_trn) in enumerate(trn_loader):\n",
    "    x_trn, y_trn = x_trn.to(device), y_trn.to(device)\n",
    "    \n",
    "    print(x_trn.view(-1, 784).shape, y_trn.shape)\n",
    "    y_pred_score = net(x_trn.view(-1,784))\n",
    "    y_pred_label = torch.argmax(y_pred_score, dim=1)\n",
    "    y_pred_label = y_pred_label.detach().cpu().numpy()\n",
    "    y_real_label = y_trn.detach().cpu().numpy()\n",
    "    print(y_real_label)\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "421dbd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0663e-02, 1.5860e-04, 4.3098e-04,  ..., 3.1206e-03, 1.6671e-03,\n",
       "         7.9995e-04],\n",
       "        [9.9682e-01, 1.0159e-08, 1.5419e-04,  ..., 4.4307e-05, 9.9347e-06,\n",
       "         9.2514e-06],\n",
       "        [4.0278e-04, 4.4199e-04, 5.0742e-02,  ..., 3.0686e-02, 1.7276e-03,\n",
       "         3.6160e-02],\n",
       "        ...,\n",
       "        [3.0885e-05, 5.8638e-04, 1.3319e-02,  ..., 1.0978e-06, 5.3008e-04,\n",
       "         2.0072e-06],\n",
       "        [7.0663e-07, 7.2564e-05, 6.9694e-06,  ..., 3.0300e-03, 2.0202e-03,\n",
       "         9.7181e-01],\n",
       "        [2.7045e-05, 9.5462e-06, 3.9834e-05,  ..., 9.8364e-01, 5.4281e-05,\n",
       "         1.5589e-02]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_score = net(x_trn.view(-1,784))\n",
    "y_pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c14d0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미리 학습한 모델의 정확도는 93.58%입니다.\n"
     ]
    }
   ],
   "source": [
    "trn_pred_results = []\n",
    "trn_real_results = []\n",
    "for i, (x_trn, y_trn) in enumerate(trn_loader):\n",
    "    x_trn = x_trn.view(-1,784).to(device)\n",
    "    y_trn = y_trn.to(device) #gpu 쓰고 있을 수도 있어서\n",
    "    \n",
    "    y_pred_score = net(x_trn)\n",
    "    y_pred_label = torch.argmax(y_pred_score, dim=1)\n",
    "    \n",
    "    y_pred_label = y_pred_label.detach().cpu().numpy()\n",
    "    y_real_label = y_trn.detach().cpu().numpy() \n",
    "    \n",
    "    trn_pred_results.extend(y_pred_label)\n",
    "    trn_real_results.extend(y_real_label)\n",
    "\n",
    "# 리스트에 넣고 마지막에 비교\n",
    "trn_pred_results = np.array(trn_pred_results)\n",
    "trn_real_results = np.array(trn_real_results)\n",
    "\n",
    "print(f'미리 학습한 모델의 정확도는 {100*np.sum(trn_pred_results==trn_real_results) / len(trn_real_results):.2f}%입니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208ea81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b86f16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7ee0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1569c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경과 시간: 0분 5초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 작업 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 예제 작업: 5초 동안 대기\n",
    "time.sleep(5)\n",
    "\n",
    "# 작업 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 경과 시간 계산\n",
    "mins, secs = epoch_time(start_time, end_time)\n",
    "print(f\"경과 시간: {mins}분 {secs}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db4207bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본이 되는 것\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, dim_in=784, dim_h1=50, dim_h2=100, dim_out=10):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_in, dim_h1, bias=True)\n",
    "        self.fc2 = nn.Linear(dim_h1, dim_h2, bias=True)\n",
    "        self.fc3 = nn.Linear(dim_h2, dim_out, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47b5d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, dim_in=784, dim_h1=50, dim_h2=100, dim_out=10):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_in, dim_h1, bias=True)\n",
    "        self.fc2 = nn.Linear(dim_h1, dim_h2, bias=True)\n",
    "        self.fc3 = nn.Linear(dim_h2, dim_out, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.fc1(x) # Step 1, 2\n",
    "        h1 = torch.sigmoid(h1) # Step 3\n",
    "        h2 = self.fc2(h1) # Step 4\n",
    "        h2 = torch.sigmoid(h2) # Step 5\n",
    "        out = self.fc3(h2) # Step 6\n",
    "        out = F.log_softmax(out) # Step 7\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df3f34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "617ffc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision에서도 MNIST데이터를 제공합니다. \n",
    "# 이 데이터를 다운 받을 디렉토리(data_path) 존재 여부를 확인하고 존재하지 않으면 생성 \n",
    "data_path = 'data2'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    \n",
    "# data 변환 방법 선언 (data transform method)\n",
    "# 아래 예시: numpy형태의 데이터를 받으면 걔를 tensor로 변환해줘!\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# dataset을 생성 (torchvision에서 제공하는 데이터를 다운 받고, 위의 방법대로 변환)\n",
    "trn_dset = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)\n",
    "tst_dset = datasets.MNIST(root=data_path, train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73a79317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 2**9\n",
    "trn_loader = DataLoader(trn_dset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "tst_loader = DataLoader(tst_dset, batch_size = BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "225f67cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = MyNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5032c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "my_opt = optim.Adam(params = model.parameters(), lr = 2e-4) #0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77df35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\AppData\\Local\\Temp\\ipykernel_21056\\773842903.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.log_softmax(out) # Step 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 3s\n",
      "\tTrain Loss: 2.284 | Test Loss: 2.232 | Test Acc: 28.590% \n",
      "Epoch: 02 | Time: 0m 3s\n",
      "\tTrain Loss: 2.146 | Test Loss: 2.020 | Test Acc: 51.970% \n",
      "Epoch: 03 | Time: 0m 3s\n",
      "\tTrain Loss: 1.866 | Test Loss: 1.697 | Test Acc: 56.520% \n",
      "Epoch: 04 | Time: 0m 3s\n",
      "\tTrain Loss: 1.557 | Test Loss: 1.413 | Test Acc: 65.530% \n",
      "Epoch: 05 | Time: 0m 3s\n",
      "\tTrain Loss: 1.301 | Test Loss: 1.184 | Test Acc: 73.450% \n",
      "Epoch: 06 | Time: 0m 3s\n",
      "\tTrain Loss: 1.097 | Test Loss: 1.004 | Test Acc: 78.330% \n",
      "Epoch: 07 | Time: 0m 3s\n",
      "\tTrain Loss: 0.938 | Test Loss: 0.862 | Test Acc: 82.370% \n",
      "Epoch: 08 | Time: 0m 3s\n",
      "\tTrain Loss: 0.812 | Test Loss: 0.747 | Test Acc: 84.530% \n",
      "Epoch: 09 | Time: 0m 4s\n",
      "\tTrain Loss: 0.709 | Test Loss: 0.654 | Test Acc: 86.330% \n",
      "Epoch: 10 | Time: 0m 4s\n",
      "\tTrain Loss: 0.626 | Test Loss: 0.580 | Test Acc: 87.330% \n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터를 n_epoch(10)번 반복하여 넣을 때 까지 학습합니다.\n",
    "n_epochs = 10\n",
    "\n",
    "# 매 epoch마다 반복\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    trn_loss = 0\n",
    "    # 매 mini-batch train data마다 반복\n",
    "    for i, (x, y) in enumerate(trn_loader):\n",
    "        # 1-(1): 모델에 입력하기 위해서 데이터의 형태 변환\n",
    "        x = x.view(-1,784).to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # 1-(2): 기존에 계산된 gradient를 0으로 reset\n",
    "        my_opt.zero_grad()\n",
    "        \n",
    "        # 1-(3): Forward Propagation\n",
    "        y_pred_prob = model(x)\n",
    "        \n",
    "        # 1-(4): Loss Calculation\n",
    "        loss = F.nll_loss(y_pred_prob, y, reduction = 'sum')\n",
    "        \n",
    "        # 1-(5): Gradient Calculation(Backprop)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 1-(6): Update parameter\n",
    "        my_opt.step()\n",
    "        \n",
    "        # 1-(7): trn_loss에 mini_batch loss를 누적해서 계산하기\n",
    "        trn_loss += loss.item()\n",
    "        \n",
    "    trn_loss /= len(trn_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    results_pred = []\n",
    "    results_real = []\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        # 매 mini-batch validation data마다 반복\n",
    "        for i, (x, y) in enumerate(tst_loader):\n",
    "            # 2-(1)\n",
    "            x = x.reshape(-1,784).to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # 2-(2)\n",
    "            y_pred_prob = model(x)\n",
    "            y_pred_label = torch.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "            # 2-(3)\n",
    "            loss = F.nll_loss(y_pred_prob, y, reduction='sum')\n",
    "            val_loss += loss\n",
    "            \n",
    "            results_pred.extend(y_pred_label.cpu().detach().numpy())\n",
    "            results_real.extend(y.cpu().detach().numpy())\n",
    "            \n",
    "        # 3.\n",
    "        val_loss /= len(tst_loader.dataset)\n",
    "        results_pred = np.array(results_pred)\n",
    "        results_real = np.array(results_real)\n",
    "        accuracy = np.sum(results_pred == results_real) / len(tst_loader.dataset)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {trn_loss:.3f} | Test Loss: {val_loss:.3f} | Test Acc: {100*accuracy:.3f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c62e38",
   "metadata": {},
   "source": [
    "각 mini-batch마다 새로운 gradient를 계산하기 전에 이전에 계산된 gradient를 초기화해야 합니다. 그렇지 않으면 오래된 gradient 값이 현재 gradient 값에 누적되어 올바른 학습이 이루어지지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d5b15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e90a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os, pickle, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9521228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, dim_in=784, dim_h1=50, dim_h2=100, dim_out=10):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_in, dim_h1, bias=True)\n",
    "        self.fc2 = nn.Linear(dim_h1, dim_h2, bias=True)\n",
    "        self.fc3 = nn.Linear(dim_h2, dim_out, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.fc1(x) # Step 1, 2\n",
    "        h1 = torch.sigmoid(h1) # Step 3\n",
    "        h2 = self.fc2(h1) # Step 4\n",
    "        h2 = torch.sigmoid(h2) # Step 5\n",
    "        out = self.fc3(h2) # Step 6\n",
    "        out = F.log_softmax(out) # Step 7\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13050a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, device):\n",
    "    model.train() # 모델을 학습모드로!\n",
    "    trn_loss = 0\n",
    "    for i, (x, y) in enumerate(data_loader):\n",
    "        # Step 1. mini-batch에서 x,y 데이터를 얻고, 원하는 device에 위치시키기\n",
    "        x = x.view(-1, 784).to(device) # x.shape: [batch_size,28,28] -> [batch_size, 784]\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Step 2. gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Forward Propagation\n",
    "        y_pred_prob = model(x)\n",
    "        \n",
    "        # Step 4. Loss Calculation\n",
    "        loss = F.nll_loss(y_pred_prob, y, reduction='sum')\n",
    "        \n",
    "        # Step 5. Gradient Calculation (Backpropagation)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step 6. Update Parameter (by Gradient Descent)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Step 7. trn_loss 변수에 mini-batch loss를 누적해서 합산\n",
    "        trn_loss += loss.item()\n",
    "        \n",
    "    # Step 8. 데이터 한 개당 평균 train loss\n",
    "    avg_trn_loss = trn_loss / len(data_loader.dataset)\n",
    "    return avg_trn_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52574938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, optimizer, device):\n",
    "    model.eval() # 모델을 평가모드로!\n",
    "    eval_loss = 0\n",
    "    \n",
    "    results_pred = []\n",
    "    results_real = []\n",
    "    with torch.no_grad(): # evaluate()함수에는 단순 forward propagation만 할 뿐, gradient 계산 필요 X.\n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "            # Step 1. mini-batch에서 x,y 데이터를 얻고, 원하는 device에 위치시키기\n",
    "            x = x.view(-1,784).to(device) # x.shape: [batch_size,28,28] -> [batch_size, 784]\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Step 2. Forward Propagation\n",
    "            y_pred_prob = model(x)\n",
    "\n",
    "            # Step 3. Loss Calculation\n",
    "            loss = F.nll_loss(y_pred_prob, y, reduction='sum')\n",
    "            \n",
    "            # Step 4. Predict label\n",
    "            y_pred_label = torch.argmax(y_pred_prob, dim=1)\n",
    "            \n",
    "            # Step 5. Save real and predicte label\n",
    "            results_pred.extend(y_pred_label.detach().cpu().numpy())\n",
    "            results_real.extend(y.detach().cpu().numpy())\n",
    "            \n",
    "            # Step 6. eval_loss변수에 mini-batch loss를 누적해서 합산\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "    # Step 7. 데이터 한 개당 평균 eval_loss와 accuracy구하기\n",
    "    avg_eval_loss = eval_loss / len(data_loader.dataset)\n",
    "    results_pred = np.array(results_pred)\n",
    "    results_real = np.array(results_real)\n",
    "    accuracy = np.sum(results_pred == results_real) / len(results_real)\n",
    "    \n",
    "    return avg_eval_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07a1f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c86f4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision에서도 MNIST데이터를 제공합니다. \n",
    "# 이 데이터를 다운 받을 디렉토리(data_path) 존재 여부를 확인하고 존재하지 않으면 생성 \n",
    "data_path = 'data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    \n",
    "# data 변환 방법 선언 (data transform method)\n",
    "# 아래 예시: numpy형태의 데이터를 받으면 걔를 tensor로 변환해줘!\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# dataset을 생성 (torchvision에서 제공하는 데이터를 다운 받고, 위의 방법대로 변환)\n",
    "trn_dset = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)\n",
    "tst_dset = datasets.MNIST(root=data_path, train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c126615",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf739231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet(dim_in=784, dim_h1=50, dim_h2=100, dim_out=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27525b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8998ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "LR = 2e-4\n",
    "BATCH_SIZE = 2**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95e14302",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = DataLoader(trn_dset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "tst_loader = DataLoader(tst_dset, batch_size = BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed15070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_opt = optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1d6c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\AppData\\Local\\Temp\\ipykernel_21056\\773842903.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.log_softmax(out) # Step 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 3s\n",
      "\tTrain Loss: 2.273 | Test Loss: 2.221 | Test Acc: 24.950% \n",
      "Epoch: 02 | Time: 0m 3s\n",
      "\tTrain Loss: 2.121 | Test Loss: 1.976 | Test Acc: 57.340% \n",
      "Epoch: 03 | Time: 0m 3s\n",
      "\tTrain Loss: 1.808 | Test Loss: 1.622 | Test Acc: 62.540% \n",
      "Epoch: 04 | Time: 0m 3s\n",
      "\tTrain Loss: 1.478 | Test Loss: 1.327 | Test Acc: 71.140% \n",
      "Epoch: 05 | Time: 0m 3s\n",
      "\tTrain Loss: 1.219 | Test Loss: 1.102 | Test Acc: 76.260% \n",
      "Epoch: 06 | Time: 0m 3s\n",
      "\tTrain Loss: 1.025 | Test Loss: 0.936 | Test Acc: 79.720% \n",
      "Epoch: 07 | Time: 0m 3s\n",
      "\tTrain Loss: 0.881 | Test Loss: 0.812 | Test Acc: 82.270% \n",
      "Epoch: 08 | Time: 0m 3s\n",
      "\tTrain Loss: 0.771 | Test Loss: 0.715 | Test Acc: 84.360% \n",
      "Epoch: 09 | Time: 0m 5s\n",
      "\tTrain Loss: 0.683 | Test Loss: 0.636 | Test Acc: 85.840% \n",
      "Epoch: 10 | Time: 0m 5s\n",
      "\tTrain Loss: 0.611 | Test Loss: 0.571 | Test Acc: 87.050% \n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    trn_loss = train(model=model, \n",
    "                     data_loader=trn_loader, \n",
    "                     optimizer=my_opt, \n",
    "                     device=device)\n",
    "    val_loss, accuracy = evaluate(model=model, \n",
    "                                  data_loader=tst_loader, \n",
    "                                  optimizer=my_opt, \n",
    "                                  device=device)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{save_dir}/my_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {trn_loss:.3f} | Test Loss: {val_loss:.3f} | Test Acc: {100*accuracy:.3f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491185c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c22f7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69b264cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2deae",
   "metadata": {},
   "source": [
    "Hint 1. Activation function들을 Pytorch코드로 변환하셔야 됩니다. (1번문제의 결과물을 활용하셔도 되고, nn.ReLU()와 같은 pytorch에서 제공하는 함수를 사용하셔도 됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c397d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    result = 1/(1+np.exp(-x))\n",
    "    return result    \n",
    "    \n",
    "def relu(x):\n",
    "    result = np.maximum(0,x)\n",
    "    return result\n",
    "\n",
    "def softmax(x):\n",
    "    c=np.max(x)\n",
    "    exp_x = np.exp(x-c) # overflow 대책\n",
    "    exp_sum = np.sum(exp_x)\n",
    "    result = exp_x/exp_sum\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f94f844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_torch(x):\n",
    "    result = 1/(1+torch.exp(-x))\n",
    "    return result\n",
    "    \n",
    "def relu_torch(x):\n",
    "    result = torch.maximum(x, torch.Tensor([0]))\n",
    "    return result\n",
    "\n",
    "def softmax1_torch(x):\n",
    "    exp_sum = torch.sum(torch.exp(x))\n",
    "    result = torch.exp(x)/exp_sum\n",
    "    return result\n",
    "\n",
    "def softmax2_torch(x):\n",
    "    c=torch.max(x)\n",
    "    exp_x = torch.exp(x-c) # overflow 대책\n",
    "    exp_sum = torch.sum(exp_x)\n",
    "    result = exp_x/exp_sum\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e82905",
   "metadata": {},
   "source": [
    "Hint 2. network에 있는 numpy array를 Pytorch tensor 형태로 변환하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ecce0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(device):\n",
    "    fpath = 'sample_weights/sample_weight.pkl'\n",
    "    with open(fpath, 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "        \n",
    "    # network변수안의 모든 key에 대해서 torch.Tensor로 형태 변경\n",
    "    \n",
    "    # GPU사용할때를 위해서 해당 tensor를 device로 옮겨놓기\n",
    "    for key in network.keys():\n",
    "        network[key] = torch.Tensor(network[key]).to(device)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43b5f4",
   "metadata": {},
   "source": [
    "Hint 3. MNIST mini-batch data는 현재 numpy array인데 Pytorch tensor 형태로 변환하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5599f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data(X, y, start_idx, end_idx):\n",
    "    x_batch = X[start_idx:end_idx]\n",
    "    y_batch = y[start_idx:end_idx]\n",
    "    # x_batch, y_batch를 torch.Tensor로 형태 변경\n",
    "    x_batch = torch.Tensor(x_batch)\n",
    "    y_batch = torch.Tensor(y_batch)\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d68a57",
   "metadata": {},
   "source": [
    "Hint 4. Pytorch에서 텐서곱은 torch.matmul()입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96d1ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(network, x):\n",
    "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    # torch의 행렬곱과 activation function을 활용하여\n",
    "    # forward propagation 나타내기\n",
    "    a1 = torch.matmul(x, w1) + b1\n",
    "    z1 = sigmoid_torch(a1)\n",
    "    a2 = torch.matmul(z1, w2) + b2\n",
    "    z2 = sigmoid_torch(a2)\n",
    "    a3 = torch.matmul(z2, w3) + b3\n",
    "    output = softmax2_torch(a3)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc70566",
   "metadata": {},
   "source": [
    "Hint 5. Pytorch에서 Tensor를 numpy array형태로 변경하는 방법은 .numpy()이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9dedc14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미리 학습한 모델의 정확도는 92.51%입니다.\n"
     ]
    }
   ],
   "source": [
    "(x_trn, y_trn), (x_tst, y_tst) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "network = init_network(device)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0,x_trn.shape[0],batch_size):\n",
    "    x_batch, _ = get_batch_data(x_trn, y_trn, i, i+batch_size)\n",
    "    \n",
    "    # x_batch를 device로 올리기 (GPU? CPU?)\n",
    "    x_batch = x_batch.to(device)\n",
    "    \n",
    "    # mini batch데이터에 대해서 forward propagation한 결과를 얻기 (pred_score_batch)\n",
    "    pred_score_batch = forward_propagation(network, x_batch)\n",
    "    \n",
    "    # torch의 argmax()를 활용해서 모델의 예측하는 레이블을 얻기(pred_label_batch)\n",
    "    pred_label_batch = torch.argmax(pred_score_batch, dim=1)\n",
    "    \n",
    "    # pred_label_batch를 numpy array형태로 변경\n",
    "    pred_label_batch = pred_label_batch.cpu().numpy()\n",
    "    \n",
    "    results.extend(pred_label_batch)\n",
    "    \n",
    "print(f'미리 학습한 모델의 정확도는 {100*np.sum(results==y_trn) / len(y_trn):.2f}%입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3f53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
